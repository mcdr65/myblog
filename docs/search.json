[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\nNoncollapsibility of the odds ratio\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nIPW-analysis\n\n\n\n\n\n\nDec 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompositions\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nSimplex as sample space: Tetrahedron for 4-part compositions\n\n\n\n\n\n\nNov 3, 2022\n\n\n\n\n\n\n  \n\n\n\n\nAber der Kaiser hat ja gar nichts an!\n\n\n\n\n\n\n\nmeinung\n\n\n\n\nGegen Identit√§tspolitik\n\n\n\n\n\n\nOct 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond linearity\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nFrom linear model to GAM\n\n\n\n\n\n\nOct 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExponential Growth\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\nexp and log\n\n\n\n\n\n\nSep 29, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Welcome!"
  },
  {
    "objectID": "posts/exponentialGrowth/index.html",
    "href": "posts/exponentialGrowth/index.html",
    "title": "Exponential Growth",
    "section": "",
    "text": "The greatest shortcoming of the human race is the inability to understand the exponential function. (Al Bartlett)"
  },
  {
    "objectID": "posts/exponentialGrowth/index.html#inzidenz-und-kumulierte-inzidenz",
    "href": "posts/exponentialGrowth/index.html#inzidenz-und-kumulierte-inzidenz",
    "title": "Exponential Growth",
    "section": "Inzidenz und kumulierte Inzidenz",
    "text": "Inzidenz und kumulierte Inzidenz\n\nCodedata<-read.csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\",check.names=FALSE)\nsw<-data[data$\"Country/Region\"==\"Switzerland\",-c(1,2,3,4)]\ncases<-as.numeric(sw[-c(1:42)])\nincid<-diff(cases)\nt<-1:length(incid)\nma <- function(x, n = 7){stats::filter(x, rep(1 / n, n), sides = 2)}  ##moving average over 7 days\nincidAv<-ma(incid)\nplot(t,incid,type=\"l\",col=\"blue\",lty=2,xlab=\"Tage\")\nlines(t,incidAv,col=\"red\",lwd=2)\n\n\nInzidenz\n\n\n\n\nCodeplot(1:length(cases),cases,type=\"l\",col=\"blue\",lwd=2,xlab=\"Tage\")\n\n\nkumulierte Indzidenz\n\n\n\n\nCodeplot(1:length(cases),log(cases),type=\"l\",col=\"blue\",lwd=2,xlab=\"Tage\")\n\n\nlog kumulierte Indzidenz"
  },
  {
    "objectID": "posts/exponentialGrowth/index.html#erste-welle-covid-19",
    "href": "posts/exponentialGrowth/index.html#erste-welle-covid-19",
    "title": "Exponential Growth",
    "section": "Erste Welle Covid-19",
    "text": "Erste Welle Covid-19\n\nCodeswisspop<-8e6\ntime<-seq(1,60,by=1)\ntag<-1:length(cases)\nT1<-1\nT2<-2\nT3<-3\nT7<-7\nx0<-100\nY1<-x0*2^(time/T1)\nY2<-x0*2^(time/T2)\nY3<-x0*2^(time/T3)\nY7<-x0*2^(time/T7)\ntime<-time+1\nplot(time,Y1,type=\"l\",ylab=\"cases\",ylim=c(100,10000),xlab=\"days\",las=1)\nlines(time,Y3,col=\"red\",lty=2)\nlines(time,Y2,lty=2)\nlines(time,Y7,lty=3)\nabline(h=swisspop,lty=5,col=\"red\") \npoints(tag,cases,type=\"l\",col=\"red\")\n\n\nInzidenz\n\n\n\n\nCodeplot(time,Y1,log=\"y\",type=\"l\",ylab=\"cases\",xlab=\"days\",axes=FALSE,ylim=c(100,40000))\nat.y <- outer(1:9, 10^(2:9))\nlab.y <- ifelse(log10(at.y) %% 1 == 0, at.y, NA)\naxis(2, at=at.y, labels=lab.y, las=2)\naxis(1,time)\nlines(time,Y2,lty=2)\nlines(time,Y7,lty=3)\nlines(time,Y3,col=\"red\",lty=2)\nabline(h=swisspop,col=\"red\",lty=3)\npoints(tag,cases,type=\"l\",col=\"red\")\n\n\nlog Inzidenz\n\n\n\n\n\nErste Welle. Example of doubling times: 1 day (solid), 2 days (dashed), 3 days (red), seven days (dotted), with reported cases Covid19 in Switzerland. Horizontal line: swiss population. On a logarithmic scale, a straight line indicates exponential growth. Quelle."
  },
  {
    "objectID": "posts/exponentialGrowth/index.html#auswirkung-vorfaktor",
    "href": "posts/exponentialGrowth/index.html#auswirkung-vorfaktor",
    "title": "Exponential Growth",
    "section": "Auswirkung Vorfaktor",
    "text": "Auswirkung Vorfaktor\nAnnahme: Verdoppelung alle drei Tage, 10 Prozent der Infizierten m√ºssen ins Spital. Die Anzahl Cases von heute sind die Anzahl Spitalpatienten in 9 Tagen, wenn mann nichts macht.\n\\(0.1\\times 2^{0.33t}=0.1\\times (2^{0.33})^t=0.1\\times 1.3^t=1.3^{\\log_{1.3}0.1}1.3^t=1.3^{t+\\log_{1.3}0.1}=1.3^{t-8.776}\\)\nAnalog kann man zeigen: Wenn die Mortalit√§tsrate bei einem Prozent der best√§tigten F√§lle liegt, dann ist die Anzahl der best√§tigten F√§lle die zu erwartende Anzahl der Todesf√§lle ca. 18 Tage sp√§ter, wenn man nichts macht.\n\\(0.01\\times 2^{0.33t}=0.01\\times (2^{0.33})^t=0.01\\times 1.3^t=1.3^{\\log_{1.3}0.01}1.3^t=1.3^{t+\\log_{1.3}0.01}=1.3^{t-17.553}\\)\n\nCodedelay<-log(0.1)/log(1.3)\ndelay\n\n[1] -8.776291\n\nCodedelay2<-log(0.01)/log(1.3)\ndelay2\n\n[1] -17.55258\n\nCodeplot(time,2^(0.33*time),ylab=\"cases\",xlab=\"days\",type=\"l\",ylim=c(0,10000),col=3)\nlines(time,0.1*2^(time/3),lty=1,col=1)\nlines(time,0.01*2^(time/3),lty=1,col=2,lwd=2)\n\n\nAuswirkung Vorfaktor"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Noncollapsibility of the odds ratio\n\n\n\n\n\n\n\n\n\nDec 2, 2023\n\n\n\n\n\n\n\n\nCompositions\n\n\n\n\n\n\n\n\n\nNov 3, 2022\n\n\n\n\n\n\n\n\nAber der Kaiser hat ja gar nichts an!\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\n\n\n\n\n\n\nBeyond linearity\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\n\n\n\n\n\n\nExponential Growth\n\n\n\n\n\n\n\n\n\nSep 29, 2022\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nSep 26, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "üëã Hi, I‚Äôm Andr√© Meichtry\nüëÄ I‚Äôm interested in philosophy, physics, quantitative research methodology and biostatistics.\nüå± I‚Äôm currently working as a statistics consultant at the School of Health Professions, Bern University of Applied Sciences.\n‚ù§Ô∏è I like üèÉ.\n\nüè¢ Berner Fachhochschule / Bern University of Applied Sciences\nDepartement Gesundheit / Department of Health Professions\nAndr√© Meichtry\nMurtenstrasse 10\n(B√ºro: Finkenhubelweg 11, Raum/Office F108)\n3008 Bern\nSwitzerland\n+41 31 848 60 18\n\nandre.meichtry@bfh.ch\nbfh.ch/gesundheit"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html",
    "href": "posts/fromLMtoSplines/index.html",
    "title": "Beyond linearity",
    "section": "",
    "text": "Triceps skinfold thickness dataset: The data are derived from an anthropometric study of 892 females under 50 years in three Gambian villages in West Africa.\n\nCodelibrary(MultiKink)\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass \"numericVector\" of class \"Mnumeric\"; definition not updated\n\nCodelibrary(ggplot2)\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\n\n\nCodedata(\"triceps\")\nheadTail(triceps)\n\n      age lntriceps triceps\n1   12.05      1.22     3.4\n2    9.91      1.39       4\n3   10.04      1.44     4.2\n4   11.49      1.44     4.2\n...   ...       ...     ...\n889  7.91      1.92     6.8\n890  7.99      1.44     4.2\n891 14.63       2.2       9\n892 30.14       2.1     8.2\n\nCodetri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#rmse-for-quadratic",
    "href": "posts/fromLMtoSplines/index.html#rmse-for-quadratic",
    "title": "Beyond linearity",
    "section": "RMSE for quadratic",
    "text": "RMSE for quadratic\n\nCodelibrary(caret)\n\nLoading required package: lattice\n\nCodeset.seed(1234)\ntrC.lm <- trainControl(method = \"repeatedcv\", \n                       number = 10,         \n                       repeats = 10)        \npol.model <- train(triceps ~ poly(age,3),\n                       data = triceps, \n                       method = \"lm\",\n                       trControl = trC.lm)    \npol.model$results[2]\n\n      RMSE\n1 3.865866"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#rmse-for-different-degrees",
    "href": "posts/fromLMtoSplines/index.html#rmse-for-different-degrees",
    "title": "Beyond linearity",
    "section": "RMSE for different degrees",
    "text": "RMSE for different degrees\n\nCodemy.pol.f <- function(x){\n    xx<-poly(triceps$age, x, raw=T)    \n    new.data  <- cbind(triceps=triceps$triceps, xx)                                 \n    pol.model <- train(triceps~., data = new.data,method = \"lm\")    \n    RMSE.cv = pol.model$results[2]\n  }\n\nt(sapply(1:10, my.pol.f))\n\n     RMSE     RMSE     RMSE     RMSE    RMSE     RMSE     RMSE     RMSE     RMSE     RMSE    \n[1,] 3.984711 4.083302 3.830449 3.77627 3.787051 3.740982 3.847184 3.803367 3.866925 3.803712\n\n\n\nCodetri.age.plot + \n   stat_smooth(method = \"lm\", \n               formula = y~poly(x,6,raw=T), size = 1)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#natural-cubic-splines-restriction-that-the-fitted-curve-linear-at-the-extremes",
    "href": "posts/fromLMtoSplines/index.html#natural-cubic-splines-restriction-that-the-fitted-curve-linear-at-the-extremes",
    "title": "Splines are beautiful",
    "section": "Natural cubic splines, restriction that the fitted curve linear at the extremes",
    "text": "Natural cubic splines, restriction that the fitted curve linear at the extremes\n\ncub.splines.ns <- lm(triceps ~ ns(age, knots = c(5,10,20,30,40)), \n                   data=triceps)\nsummary(cub.splines.ns)\n\n\nCall:\nlm(formula = triceps ~ ns(age, knots = c(5, 10, 20, 30, 40)), \n    data = triceps)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.4875  -1.6873  -0.3665   1.1146  22.8643 \n\nCoefficients:\n                                       Estimate Std. Error t value Pr(>|t|)\n(Intercept)                              8.3811     0.5219  16.059  < 2e-16\nns(age, knots = c(5, 10, 20, 30, 40))1  -3.5592     0.6712  -5.303 1.44e-07\nns(age, knots = c(5, 10, 20, 30, 40))2   5.7803     1.0379   5.569 3.39e-08\nns(age, knots = c(5, 10, 20, 30, 40))3   5.5118     0.9416   5.853 6.78e-09\nns(age, knots = c(5, 10, 20, 30, 40))4   6.9070     0.9050   7.632 5.99e-14\nns(age, knots = c(5, 10, 20, 30, 40))5   5.4136     1.3783   3.928 9.24e-05\nns(age, knots = c(5, 10, 20, 30, 40))6   6.6460     1.0829   6.137 1.27e-09\n\nResidual standard error: 3.759 on 885 degrees of freedom\nMultiple R-squared:  0.4199,    Adjusted R-squared:  0.416 \nF-statistic: 106.8 on 6 and 885 DF,  p-value: < 2.2e-16\n\n\n\ntri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot +\n    stat_smooth(method = \"lm\", \n               formula = y~bs(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"green\") + \n    stat_smooth(method = \"lm\", \n               formula = y~ns(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"red\")\n\n\npolynomial cubic splines, natural cubic splines"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#connecting-the-lines",
    "href": "posts/fromLMtoSplines/index.html#connecting-the-lines",
    "title": "Splines are beautiful",
    "section": "Connecting the lines",
    "text": "Connecting the lines\nWe want continuity in the knots, this will be the model:\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2I_{x_i\\geq 5}(x_i-5)+\\cdots+\\beta_6I_{x_i \\geq 40}(x_i-40) + \\epsilon_i\\]\nBy ‚Äúhand‚Äù or with B-splines: splines::bs()\n\nCodepred7 <- predict(lm(triceps~ age + I((age-5)*(age>=5)) +\n                                   I((age-10)*(age >= 10)) +\n                                   I((age-20)*(age >= 20)) +\n                                   I((age-30)*(age >= 30)) +\n                                  I((age-40)*(age >= 40)),\n                    data = triceps))\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred7, x=age), size = 1, col=\"red\")\n\n\n\n\n\nCodelibrary(splines)\npred.lm.bs <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\n\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#piecewise-quadratic",
    "href": "posts/fromLMtoSplines/index.html#piecewise-quadratic",
    "title": "Splines are beautiful",
    "section": "Piecewise quadratic",
    "text": "Piecewise quadratic\n\npred.quad <- predict(lm(triceps~ age + I(age^2) + \n                    I((age-5)*(age>=5)) + I((age-5)^2*(age>=5)) +\n                    I((age-10)*(age >= 10)) + I((age-10)^2*(age>=10)) +\n                    I((age-20)*(age >= 20)) + I((age-20)^2*(age>=20)) +\n                    I((age-30)*(age >= 30)) + I((age-30)^2*(age>=30)) +\n                    I((age-40)*(age >= 40)) + I((age-40)^2*(age>=40)),\n                    data = triceps))\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.quad, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#einfacher-mit-bs",
    "href": "posts/fromLMtoSplines/index.html#einfacher-mit-bs",
    "title": "Splines are beautiful",
    "section": "einfacher mit bs()!",
    "text": "einfacher mit bs()!\n\nlibrary(splines)\npred.lm.bs <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\n\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#not-smooth-yet-only-quadratic-terms",
    "href": "posts/fromLMtoSplines/index.html#not-smooth-yet-only-quadratic-terms",
    "title": "Splines are beautiful",
    "section": "Not smooth yet, only quadratic terms",
    "text": "Not smooth yet, only quadratic terms\n\npred.quadsmooth <- predict(lm(triceps~ age + I(age^2) + \n                    I((age-5)^2*(age>=5)) +\n                    I((age-10)^2*(age>=10)) +\n                    I((age-20)^2*(age>=20)) +\n                    I((age-30)^2*(age>=30)) +\n                    I((age-40)^2*(age>=40)),\n                    data = triceps))\n#einfacher mit `bs()`!\nlibrary(splines)\npred.quadsmooth2 <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=2), data=triceps))                        \ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth2, x=age), size = 1, col=\"blue\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#b-splines",
    "href": "posts/fromLMtoSplines/index.html#b-splines",
    "title": "Splines are beautiful",
    "section": "B-splines",
    "text": "B-splines\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x^2+\\beta_3x^3+\\beta_4I_{x_i\\geq 5}(x_i-5)^3+\\cdots+\\beta_9I_{x_i \\geq 40}(x_i-40)^3 + \\epsilon_i\\]\n\nCodecub.splines.bs <- lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree = 3), data=triceps)\nsummary(cub.splines.bs)\n\n\nCall:\nlm(formula = triceps ~ bs(age, knots = c(5, 10, 20, 30, 40), \n    degree = 3), data = triceps)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.5234  -1.6912  -0.2917   1.1356  23.0922 \n\nCoefficients:\n                                                   Estimate Std. Error t value Pr(>|t|)\n(Intercept)                                          6.9598     0.9729   7.154 1.77e-12\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)1   2.5367     1.7154   1.479   0.1396\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)2  -0.3032     0.9629  -0.315   0.7529\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)3  -1.9092     1.2993  -1.469   0.1421\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)4   7.4056     1.2179   6.081 1.78e-09\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)5   6.1050     1.4043   4.347 1.54e-05\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)6  10.1770     1.5427   6.597 7.23e-11\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)7   3.9428     1.9082   2.066   0.0391\nbs(age, knots = c(5, 10, 20, 30, 40), degree = 3)8  10.1473     1.7545   5.784 1.01e-08\n\nResidual standard error: 3.743 on 883 degrees of freedom\nMultiple R-squared:  0.4261,    Adjusted R-squared:  0.4209 \nF-statistic: 81.94 on 8 and 883 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#natural-splines-restriction-that-the-fitted-curve-linear-at-the-extremes",
    "href": "posts/fromLMtoSplines/index.html#natural-splines-restriction-that-the-fitted-curve-linear-at-the-extremes",
    "title": "Beyond linearity",
    "section": "Natural splines, restriction that the fitted curve linear at the extremes",
    "text": "Natural splines, restriction that the fitted curve linear at the extremes\n\nCodecub.splines.ns <- lm(triceps ~ ns(age, knots = c(5,10,20,30,40)), data=triceps)\n\n\n\nCodetri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot +\n    stat_smooth(method = \"lm\", \n               formula = y~bs(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"green\") + \n    stat_smooth(method = \"lm\", \n               formula = y~ns(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"red\")\n\n\npolynomial cubic splines, natural cubic splines"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#with-b-splines-splinesbs",
    "href": "posts/fromLMtoSplines/index.html#with-b-splines-splinesbs",
    "title": "Splines are beautiful",
    "section": "With B-splines: splines::bs()\n",
    "text": "With B-splines: splines::bs()\n\n\nlibrary(splines)\npred.lm.bs <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\n\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#piecewise-quadratic-polynomial",
    "href": "posts/fromLMtoSplines/index.html#piecewise-quadratic-polynomial",
    "title": "Beyond linearity",
    "section": "Piecewise quadratic polynomial",
    "text": "Piecewise quadratic polynomial"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#continuous-piecewise",
    "href": "posts/fromLMtoSplines/index.html#continuous-piecewise",
    "title": "Beyond linearity",
    "section": "Continuous piecewise",
    "text": "Continuous piecewise\nLet us define a truncated power basis function per knot \\(\\xi\\),\n\\[h(x, \\xi)=(x-\\xi)_{+}=\n\\begin{cases}\n  x-\\xi, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else}.\n\\end{cases}\n\\]\nThe continuous piecewise regression equation is\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2 h(x_i,5)+\\cdots+\\beta_6 h(x_i,40) + \\epsilon_i\\]\nThis can be done -by hand- or with B-splines: splines::bs()\n\nCodepred7 <- predict(lm(triceps~ age + I((age-5)*(age>=5)) +\n                                   I((age-10)*(age >= 10)) +\n                                   I((age-20)*(age >= 20)) +\n                                   I((age-30)*(age >= 30)) +\n                                  I((age-40)*(age >= 40)),\n                    data = triceps))\nlibrary(splines)\npred.lm.bs <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred7+.2, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#cubic-b-splines",
    "href": "posts/fromLMtoSplines/index.html#cubic-b-splines",
    "title": "Beyond linearity",
    "section": "Cubic B-splines",
    "text": "Cubic B-splines\nMost often, cubic splines are used. Adding the following truncated power basis function per knot\n\\[h(x, \\xi_i)=(x-\\xi_i)_{+}^3=\n\\begin{cases}\n  (x-\\xi_i)^3, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else}\n\\end{cases}\n\\]\nto the model for a cubic polynomial will lead to a discontinuity in only the third derivative at \\(\\xi\\); the function will remain continuous, with continuous first and second derivatives, at each of the knots:\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x^2+\\beta_3x^3+\\beta_4h(x_i,5)+\\cdots+\\beta_8h(x_i,40)^3 + \\epsilon_i\\]\nA cubic spline has \\(K+4\\) parameters.\n\nCodecub.splines.bs <- lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree = 3), data=triceps)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#quadratic-spline",
    "href": "posts/fromLMtoSplines/index.html#quadratic-spline",
    "title": "Beyond linearity",
    "section": "Quadratic spline",
    "text": "Quadratic spline\nWith\n\\[h(x, \\xi)=(x-\\xi)_{+}^2=\n\\begin{cases}\n  (x-\\xi)^2, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n\\]\nwe have as regression equation \\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3 h(x_i,5)+\\cdots+\\beta_7 h(x_i,40) + \\epsilon_i\\]\n\nCodepred.quadsmooth <- predict(lm(triceps~ age + I(age^2) + \n                    I((age-5)^2*(age>=5)) +\n                    I((age-10)^2*(age>=10)) +\n                    I((age-20)^2*(age>=20)) +\n                    I((age-30)^2*(age>=30)) +\n                    I((age-40)^2*(age>=40)),\n                    data = triceps))\npred.quadsmooth2 <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=2), data=triceps))                        \ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth2+.2, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#cubic-spline",
    "href": "posts/fromLMtoSplines/index.html#cubic-spline",
    "title": "Beyond linearity",
    "section": "Cubic Spline",
    "text": "Cubic Spline\nMost often, cubic splines are used. Adding the following truncated power basis function per knot,\n\\[h(x, \\xi)=(x-\\xi)_{+}^3=\n\\begin{cases}\n  (x-\\xi)^3, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n\\]\nto the model for a cubic polynomial will lead to a discontinuity in only the third derivative at \\(\\xi\\); the function will remain continuous, with continuous first and second derivatives, at each of the knots:\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3x_i^3+\\beta_4h(x_i,5)+\\cdots+\\beta_8h(x_i,40) + \\epsilon_i\\]\nOne can show that a cubic spline has \\(K+4\\) parameters."
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#natural-splines",
    "href": "posts/fromLMtoSplines/index.html#natural-splines",
    "title": "Beyond linearity",
    "section": "Natural splines",
    "text": "Natural splines\nNatural splines have an additional restriction that the fitted curve linear at the extremes\n\nCodetri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot +\n    stat_smooth(method = \"lm\", \n               formula = y~bs(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"green\") + \n    stat_smooth(method = \"lm\", \n               formula = y~ns(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"red\")\n\n\npolynomial cubic splines (green), natural cubic splines (red)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#continuous-piecewise-linear-regression",
    "href": "posts/fromLMtoSplines/index.html#continuous-piecewise-linear-regression",
    "title": "Beyond linearity",
    "section": "Continuous piecewise linear regression",
    "text": "Continuous piecewise linear regression\nWe want a continuous function. Let us define a truncated power basis function (here of degree=1) per knot \\(\\xi\\),\n\\[h(x, \\xi)=(x-\\xi)^1_{+}=\n\\begin{cases}\n  x-\\xi, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else}.\n\\end{cases}\n\\]\nThe continuous piecewise regression equation is\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2 h(x_i,5)+\\cdots+\\beta_6 h(x_i,40) + \\epsilon_i\\]\nThis can be done -by hand- or with B-splines splines::bs()\n\nCodepred7 <- predict(lm(triceps~ age + I((age-5)*(age>=5)) +\n                                   I((age-10)*(age >= 10)) +\n                                   I((age-20)*(age >= 20)) +\n                                   I((age-30)*(age >= 30)) +\n                                  I((age-40)*(age >= 40)),\n                    data = triceps))\nlibrary(splines)\npred.lm.bs <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred7+.2, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#natural-spline",
    "href": "posts/fromLMtoSplines/index.html#natural-spline",
    "title": "Beyond linearity",
    "section": "Natural Spline",
    "text": "Natural Spline\nNatural splines have an additional restriction that the fitted curve linear at the extremes, splines::ns()\n\nCodecub.splines.bs <- lm(triceps ~ bs(age, knots = c(5,10,20,30,40)), data=triceps)\ncub.splines.ns <- lm(triceps ~ ns(age, knots = c(5,10,20,30,40)), data=triceps)\n\n\n\nCodetri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot +\n    stat_smooth(method = \"lm\", \n               formula = y~bs(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"green\") + \n    stat_smooth(method = \"lm\", \n               formula = y~ns(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"red\")\n\n\npolynomial cubic splines (green), natural cubic splines (red)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#lambda-determined-with-cross-validation",
    "href": "posts/fromLMtoSplines/index.html#lambda-determined-with-cross-validation",
    "title": "Beyond linearity",
    "section": "\n\\(\\lambda\\) determined with cross-validation",
    "text": "\\(\\lambda\\) determined with cross-validation\n\nCodesspline <- smooth.spline(x=triceps$age, y=triceps$triceps, cv=TRUE)\n\nWarning in smooth.spline(x = triceps$age, y = triceps$triceps, cv = TRUE): cross-validation with non-unique 'x' values\nseems doubtful\n\nCodeplot(triceps$age, triceps$triceps)\nlines(sspline, lwd=3,col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#no-smooth-and-max-smooth",
    "href": "posts/fromLMtoSplines/index.html#no-smooth-and-max-smooth",
    "title": "Beyond linearity",
    "section": "No smooth and max smooth",
    "text": "No smooth and max smooth\n\nCodessplineNosmooth <- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=0)\nssplineMaxsmooth <- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=100)\nplot(triceps$age, triceps$triceps)\nlines(ssplineNosmooth, lwd=2,col=\"red\")\nlines(ssplineMaxsmooth, lwd=2,col=\"blue\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#the-extremes-no-smooth-and-max-smooth",
    "href": "posts/fromLMtoSplines/index.html#the-extremes-no-smooth-and-max-smooth",
    "title": "Beyond linearity",
    "section": "The extremes: no smooth and max smooth",
    "text": "The extremes: no smooth and max smooth\n\nCodessplineNosmooth <- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=0)\nssplineMaxsmooth <- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=100)\nplot(triceps$age, triceps$triceps)\nlines(ssplineNosmooth, lwd=2,col=\"red\")\nlines(ssplineMaxsmooth, lwd=2,col=\"blue\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#polynomial-regression",
    "href": "posts/fromLMtoSplines/index.html#polynomial-regression",
    "title": "Beyond linearity",
    "section": "Polynomial regression",
    "text": "Polynomial regression\nUsing poly() in lm():\n\nCodemodel.cubic.poly <- lm(triceps~poly(age,3,raw=TRUE),data=triceps)\n## the same model:\n## model.cubic <- lm(triceps~age + I(age^2) + I(age^3),\n##                   data=triceps)\ntri.age.plot + \n   stat_smooth(method = \"lm\", \n               formula = y~poly(x,3,raw=T), size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead."
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#cross-validation-of-different-polynomials",
    "href": "posts/fromLMtoSplines/index.html#cross-validation-of-different-polynomials",
    "title": "Beyond linearity",
    "section": "Cross-validation of different polynomials",
    "text": "Cross-validation of different polynomials\nRMSE for quadratic\n\nCodelibrary(caret)\n\nLoading required package: lattice\n\nCodeset.seed(1234)\ntrC.lm <- trainControl(method = \"repeatedcv\", \n                       number = 10,         \n                       repeats = 10)        \npol.model <- train(triceps ~ poly(age,3),\n                       data = triceps, \n                       method = \"lm\",\n                       trControl = trC.lm)    \npol.model$results[2]\n\n   RMSE\n1 3.866\n\n\nRMSE for different degrees\n\nCodemy.pol.f <- function(x){\n    xx<-poly(triceps$age, x, raw=T)    \n    new.data  <- cbind(triceps=triceps$triceps, xx)                                 \n    pol.model <- train(triceps~., data = new.data,method = \"lm\")    \n    RMSE.cv = pol.model$results[2]\n  }\n\nt(sapply(1:10, my.pol.f))\n\n     RMSE  RMSE  RMSE RMSE  RMSE  RMSE  RMSE  RMSE  RMSE  RMSE \n[1,] 3.985 4.083 3.83 3.776 3.787 3.741 3.847 3.803 3.867 3.804\n\n\n\nCodetri.age.plot + \n   stat_smooth(method = \"lm\", \n               formula = y~poly(x,6,raw=T), size = 1)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#piecewise-linear-regression",
    "href": "posts/fromLMtoSplines/index.html#piecewise-linear-regression",
    "title": "Beyond linearity",
    "section": "Piecewise linear regression",
    "text": "Piecewise linear regression\nInstead of fitting a high-degree polynomial over the entire range of \\(X\\), piecewise polynomial regression involves fitting separate low-degree polynomials over different regions of \\(X\\). For example, a piecewise cubic polynomial works by fitting a cubic regression model of the form\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3x_i^3+\\epsilon_i,\\]\nwhere the coefficients differ in different parts of the range of \\(X\\). The points where the coefficients change are called knots \\(\\xi_k\\), \\(k=1,\\dots,K\\).\nLet us begin with a piecewise linear (degree=1):\n\nCodepred1 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age<5,]))\npred2 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age >=5 & triceps$age<10,]))\npred3 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=10 & triceps$age<20,]))\npred4 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=20 & triceps$age<30,]))\npred5 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=30 & triceps$age<40,]))\npred6 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=40,]))\ntri.age.plot + \n  geom_line(data=triceps[triceps$age<5,], \n            aes(y = pred1, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age >=5 & triceps$age<10,], \n            aes(y = pred2, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=10 & triceps$age<20,], \n            aes(y = pred3, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=20 & triceps$age<30,], \n            aes(y = pred4, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=30 & triceps$age<40,], \n            aes(y = pred5, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=40,], \n            aes(y = pred6, x=age), size = 1, col=\"blue\")\n\n\n\n\nContinuous piecewise linear regression\nWe want a continuous function. Let us define a truncated power basis function (here of degree=1) per knot \\(\\xi\\),\n\\[h(x, \\xi)=(x-\\xi)^1_{+}=\n\\begin{cases}\n  x-\\xi, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else}.\n\\end{cases}\n\\]\nThe continuous piecewise regression equation is\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2 h(x_i,5)+\\cdots+\\beta_6 h(x_i,40) + \\epsilon_i\\]\nThis can be done -by hand- or with B-splines splines::bs()\n\nCodepred7 <- predict(lm(triceps~ age + I((age-5)*(age>=5)) +\n                                   I((age-10)*(age >= 10)) +\n                                   I((age-20)*(age >= 20)) +\n                                   I((age-30)*(age >= 30)) +\n                                  I((age-40)*(age >= 40)),\n                    data = triceps))\nlibrary(splines)\npred.lm.bs <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred7+.2, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#splines",
    "href": "posts/fromLMtoSplines/index.html#splines",
    "title": "Beyond linearity",
    "section": "Splines",
    "text": "Splines\nQuadratic spline\nWith\n\\[h(x, \\xi)=(x-\\xi)_{+}^2=\n\\begin{cases}\n  (x-\\xi)^2, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n\\]\nwe have as regression equation \\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3 h(x_i,5)+\\cdots+\\beta_7 h(x_i,40) + \\epsilon_i\\]\n\nCodepred.quadsmooth <- predict(lm(triceps~ age + I(age^2) + \n                    I((age-5)^2*(age>=5)) +\n                    I((age-10)^2*(age>=10)) +\n                    I((age-20)^2*(age>=20)) +\n                    I((age-30)^2*(age>=30)) +\n                    I((age-40)^2*(age>=40)),\n                    data = triceps))\npred.quadsmooth2 <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=2), data=triceps))                        \ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth2+.2, x=age), size = 1, col=\"red\")\n\n\n\n\nCubic Spline\nMost often, cubic splines are used. Adding the following truncated power basis function per knot,\n\\[h(x, \\xi)=(x-\\xi)_{+}^3=\n\\begin{cases}\n  (x-\\xi)^3, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n\\]\nto the model for a cubic polynomial will lead to a discontinuity in only the third derivative at \\(\\xi\\); the function will remain continuous, with continuous first and second derivatives, at each of the knots:\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3x_i^3+\\beta_4h(x_i,5)+\\cdots+\\beta_8h(x_i,40) + \\epsilon_i\\]\nOne can show that a cubic spline has \\(K+4\\) parameters.\nNatural Spline\nNatural splines have an additional restriction that the fitted curve linear at the extremes, splines::ns()\n\nCodecub.splines.bs <- lm(triceps ~ bs(age, knots = c(5,10,20,30,40)), data=triceps)\ncub.splines.ns <- lm(triceps ~ ns(age, knots = c(5,10,20,30,40)), data=triceps)\n\n\n\nCodetri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot +\n    stat_smooth(method = \"lm\", \n               formula = y~bs(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"green\") + \n    stat_smooth(method = \"lm\", \n               formula = y~ns(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"red\")\n\n\npolynomial cubic splines (green), natural cubic splines (red)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#smoothing-splines",
    "href": "posts/fromLMtoSplines/index.html#smoothing-splines",
    "title": "Beyond linearity",
    "section": "Smoothing splines",
    "text": "Smoothing splines\nAvoids the knot selection problem completely by using a maximal set of knots. The complexity of the fit is controlled by regularization. Problem: among all functions \\(f(x)\\) with two continuous derivatives, find one that minimizes the penalized residual sum of squares\n\\[\n  RSS(f,\\lambda)=\\sum_{i=1}^N(y_i-f(x_i))^2+\\lambda[f''(t)]^2dt\n\\tag{1}\\]\nwhere \\(\\lambda\\) is a fixed smoothing parameter. The first term measures closeness to the data, while the second term penalizes curvature in the function, and \\(\\lambda\\) establishes a tradeoff between the two. Special cases: \\(\\lambda=0\\) (no constraint on \\(f\\)) and \\(\\lambda=\\infty\\) (\\(f\\) has to be linear).\nThe function \\(f(x)\\) that minimizes (Equation¬†1) can be shown to have some special properties: it is a piecewise cubic polynomial with knots at the unique values of \\(x_1,\\dots,x_n\\) and continuous first and second derivatives at each knot. Furthermore, it is linear in the region outside of the extreme knots. In other words, the function \\(f(x)\\) that minimizes (Equation¬†1) is a natural cubic spline with knots at \\(x_1,\\dots,x_n\\) ! However, it is not the same natural cubic spline that one would get if one applied the basis function approach described above ‚Äì rather, it is a shrunken version of such a natural cubic spline, where the value of the tuning parameter \\(\\lambda\\) in (Equation¬†1) controls the level of shrinkage.\nSmoothing splines are implemented in smooth.spline().\n\n\\(\\lambda\\) determined with cross-validation\n\nCodesspline <- smooth.spline(x=triceps$age, y=triceps$triceps, cv=TRUE)\n\nWarning in smooth.spline(x = triceps$age, y = triceps$triceps, cv = TRUE): cross-validation with non-unique 'x' values seems doubtful\n\nCodeplot(triceps$age, triceps$triceps)\nlines(sspline, lwd=3,col=\"red\")\n\n\n\n\nThe extremes: no smooth and max smooth\n\nCodessplineNosmooth <- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=0)\nssplineMaxsmooth <- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=100)\nplot(triceps$age, triceps$triceps)\nlines(ssplineNosmooth, lwd=2,col=\"red\")\nlines(ssplineMaxsmooth, lwd=2,col=\"blue\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#generalized-additive-model",
    "href": "posts/fromLMtoSplines/index.html#generalized-additive-model",
    "title": "Beyond linearity",
    "section": "Generalized additive model",
    "text": "Generalized additive model\nUsing mgcv::gam()\n\nCodelibrary(mgcv)\n\nLoading required package: nlme\n\n\nThis is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'.\n\nCodegamtri<-gam(triceps~s(age,bs=\"cr\"),data=triceps)\nsummary(gamtri)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ntriceps ~ s(age, bs = \"cr\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)    9.702      0.126    77.3   <2e-16\n\nApproximate significance of smooth terms:\n        edf Ref.df    F p-value\ns(age) 6.71   7.54 85.6  <2e-16\n\nR-sq.(adj) =  0.419   Deviance explained = 42.3%\nGCV =  14.18  Scale est. = 14.057    n = 892\n\nCodeplot(gamtri)"
  },
  {
    "objectID": "posts/logratioGeometry/index.html",
    "href": "posts/logratioGeometry/index.html",
    "title": "Compositions",
    "section": "",
    "text": "Sample space of compositional data\nThe sample space of compositional data with \\(D\\) parts is a simplex \\(\\mathcal{S}^D\\) of dimension \\(D-1\\):\n\\(\\mathcal{S}^D=\\{\\mathbf{x}=[x_1,x_2,\\dots,x_D]\\in \\mathbb{R}^D \\mid x_i>0, i=1,2,\\dots,D; \\sum_{i=1}^Dx_i=\\mathcal{k}\\}\\)\nThe only information is given by the ratios between components, so the information of a composition is preserved under multiplication by any positive constant. Therefore, the sample space of compositional data can always be assumed to be a standard simplex, i.e.¬†\\(\\mathcal{k} = 1\\).\nNormalization to the standard simplex is called closure and is\n\\(\\mathcal{C}[x_1,x_2,\\dots,x_D]=\\left[\\frac{x_1}{\\sum_{i=1}^D x_i},\\frac{x_2}{\\sum_{i=1}^D x_i}, \\dots,\\frac{x_D}{\\sum_{i=1}^D x_i}\\right]\\)\nExample\n4 Raters rated a 4-part-composition on \\(n=20\\) subjects. See the interactive Tetrahedron\n\nCodeplot3D(datAitch,col=as.numeric(Rater),size=5,axes=TRUE,coors=TRUE)\n3D plot"
  },
  {
    "objectID": "posts/BeratungBegin/index.html",
    "href": "posts/BeratungBegin/index.html",
    "title": "Statistik Beratung G",
    "section": "",
    "text": "\\[\n\\def\\RR{{\\textsf{R}}}\n\\def\\lx{{\\LaTeX}}\n\\]\n\n\nSprechstunden\n\nMontag 10-12\nDienstag 10-12\nDonnerstag 10-12\n\n\n\nOrt\n\nFinkenhubelweg 11, Raum/Office F108\nMS Teams\n\n\n\nAnfrage\nKurzes Mail an andre.meichtry@bfh.ch mit Angabe: + Einheit (Fachbereich, Institut) + Forschung oder Lehre + Projekt / Thema + Stadium (Planung, Analyse, Interpretation, Publikation)\n\n\nSoftware\n\nStatistik: R (plattformunabh√§ngig), JAGS (MCMC)\nBetriebsystem: Windows, Linux (Ubuntu)\nEditoren: RStudio, EMACS (ESS)\nLiterate Programming: \\(\\lx\\) und R-Markdown mit knitr\nVersionsverwaltung: Git, GitHub"
  },
  {
    "objectID": "posts/gendern/index.html",
    "href": "posts/gendern/index.html",
    "title": "Aber der Kaiser hat ja gar nichts an!",
    "section": "",
    "text": "In Zeiten, in denen ‚Äì an vom Steuerzahler finanzierten Hochschulen ‚Äì Sprachleitfaden verteilt werden, scheint es doch wichtig, Gegendruck auch aus der politischen Mitte ‚Äì also nicht nur von der extremen Rechten ‚Äì aufzubauen. Es ist nicht die Aufgabe staatlicher Institutionen, an der Verbreitung von Ideologien mitzuwirken und Vorgaben zu machen, was gute Sprache ist. Sprachpolitik zu betreiben ist aus meiner Sicht etwas vom Schlimmsten, was eine Hochschule machen kann.\nDas grammatikalische bildet nicht das biologische Geschlecht ab. Diese einfache Tatsache wird von Linguistik der Genderist*innen geleugnet. Wer sich z.B. in der Klimadebatte gleich verhielte wie die Gender-Aktivisten mit der Sprache, w√ºrde sofort (und zurecht) als Wissenschaftsleugner diffamiert. Auch sind die vorgebrachten Assoziationsstudien gegen das generische Maskulinum wenig √ºberzeugend:\n\nUm die mangelnde Eignung des generischen Maskulinums zum inklusiven Formulieren vorzuf√ºhren, wird immer wieder gerne folgende Frage pr√§sentiert: ‚ÄûWer ist dein Lieblingsschauspieler?‚Äú (Stahlberg et al., 2001). Werden auf diese Frage √ºberwiegend m√§nnliche Schauspieler genannt, so werten Bef√ºrworter des Genderns dies als Beleg daf√ºr, dass generische Maskulina vorrangig die Vorstellung von M√§nnern ausl√∂sen. Allerdings ist diese Frage nicht im Geringsten geeignet, die Untauglichkeit des inklusiven Maskulinums zu demonstrieren. Denn diese Frage ist keine typische Verwendung des generischen Maskulinums. W√ºrde man ganz allgemein nach Lieblingsschauspielern fragen, so lautete die korrekte Formulierung ‚ÄûWer/welche sind deine Lieblingsschauspieler?‚Äú (Frage im Plural!). Im Singular w√ºrde man entweder fragen ‚ÄûWer ist deine Lieblingsschauspielerin?‚Äú oder ‚ÄûWer ist dein m√§nnlicher Lieblingsschauspieler?‚Äú Das generische Maskulinum wird bei allgemeinen Aussagen verwendet ‚Äì nicht, wenn konkrete Personen gemeint sind (wie in der Frage nach dem Lieblingsschauspieler).\n\nLetztendlich ist es bei vielen die Angst, als frauenfeindlich (oder feindlich anderen sozialen Geschlechtern gegen√ºber) dazustehen, die es √ºberhaupt erm√∂glicht, dass solche Sprachpolitik an den Hochschulen betrieben werden kann:\n\nVielleicht endet die Geschichte des geschlechtergerechten Sprachumbaus mit all seinen grotesken Ausw√ºchsen eines Tages wie Andersens M√§rchen vom Kaiser und seinen neuen Kleidern. Dort ist es bekanntlich ein Kind, das am Ende ausruft: ‚ÄûAber der Kaiser hat ja gar nichts an!‚Äú und dem Spuk damit ein Ende macht. Zuvor wollte in dem M√§rchen niemand eingestehen, dass er √ºberhaupt keine Kleider sieht, weil er Angst hatte, in diesem Fall f√ºr dumm zu gelten. Beim Gendern ist es unsere Angst, von den anderen f√ºr ‚Äûfrauenfeindlich‚Äú gehalten zu werden oder nicht auf der H√∂he der Zeit zu sein, die viele mitlaufen l√§sst. Dabei ist die geschlechtergerechte Sprache noch nicht einmal ein ‚Äûneues Kleid‚Äú, sondern ein √ºber 40 Jahre altes Konzept, bei dem die Frage erlaubt sein muss, was es heute noch f√ºr ein gleichberechtigtes Miteinander der Geschlechter zu leisten vermag.\n\nF√ºr Tomas Kubelik ist die Sprache unschuldig. Hier ein unterhaltsamer, humorvoller und gut aufgebauter Vortrag. Sein aus meiner Sicht nachvollziehbares Fazit ist:\n\nAlle Formen des Genderns sind unbrauchbar. Sie sind in sich widerspr√ºchlich, sie sind nicht konsequent durchf√ºhrbar, sie stossen an die Grenzen von Logik, Praktikabilit√§t und Akzeptanz. Sie sind un√§sthetisch, un√∂konomisch und irref√ºhrend. (Tomas Kubelik, Vortrag und Text)\n\nF√ºr Ingo Meyer (Das M√§rchen vom Gendersterntaler) ist das Hauptargument gegen das Gendern:\n\nSprache entwickelt sich seit Jahrhunderten. Was funktioniert, setzt sich durch; was die Verst√§ndigung erschwert, wird abgeschliffen. Nie ist es ohne Schaden gelungen, diesen unbewussten Akt nachzuahmen. Zwar stimmt es: Wenn ich die Meldung ‚ÄûSonntagsausfl√ºgler dr√§ngten ins Gr√ºne‚Äú lese, stelle ich mir die Menschen derzeit vorwiegend wei√ü vor. Um diesen Satz f√ºr mich ‚Äûgerechter‚Äú zu machen, br√§uchte ich also vielerlei Hinweise. Gerecht in diesem Sinne w√§re eine Formulierung wie ‚ÄûDie LSBTI+, PoC, alte und junge Menschen inkludierenden Sonntagsausfl√ºgler*innen dr√§ngten ins Gr√ºne‚Äú. Das ist offensichtlich absurd. Sprache hat nicht die Aufgabe, von Dritten erw√ºnschte Bedeutungen in unsere K√∂pfe zu pflanzen. Es gibt keine geschlechtergerechte Sprache. Es gibt √ºberhaupt keine gerechte Sprache. Es steht uns aber frei, die vorhandene Sprache gerecht zu verwenden.\n\nEin einfach und klar geschriebenes Buch ist auch: Fabian Payr: Von Menschen und Mensch*innen. 20 gute Gr√ºnde, mit dem Gendern aufzuh√∂ren:\n\n‚ÄûStudentin kann nur deshalb ‚Äöweibliche Person, die studiert‚Äò bedeuten, weil das zugrunde liegende Wort Student ‚ÄöPerson, die studiert‚Äò bedeutet und nicht etwa ‚Äöm√§nnliche Person, die studiert‚Äò‚Äú (Lieb & Richter, 1990, S. 150).\n\nNat√ºrlich lehnen auch sehr viele Frauen das Gendern ab. Pers√∂nlich kenne ich keine einzige Frau in meinem nicht-akademischen Umfeld, die Gendern gut findet.\n\nIch bin eine Frau und ich f√ºhle mich bel√§stigt von den In-Endungen, von dem Binnen-I und dem ganzen syntaktischen Gleichberechtigungsgefummel. Die fast extremistischen Z√ºge des Verweiblichungswahns von Sprache haben wohl mit der Tradition des Alice Schwarzer Opferfeminismus zu tun. Offenbar haben bis heute manche mental nicht aus der weiblichen Opferrolle herausgefunden. Als Therapie und als Beleg des weiblichen Selbstbewusstseins fordere ich das generische Maskulinum daher zur√ºck. Ich mache auch gleich ernst damit und verabschiede mich an dieser Stelle im maskulinen Gestus von Ihnen, lieber Leser, liebe B√ºrger, liebe Staatssekret√§re, liebe Feministinnen, liebe Kritiker. Das f√ºhlt sich gut an. (Dagmar Rosenfeld, in der Wochenzeitung die Zeit (2014) in einem ‚ÄûAufschrei‚Äú)\n\nInzwischen wird auch in Frage gestellt, dass das biologische Geschlecht zweiwertig ist, die Biologie an sich wird als Naturwissenschaft nicht mehr ernst genommen. Ich h√§tte nat√ºrlich nie gedacht, dass ich mich eines Tages daf√ºr rechtfertigen muss, im Statistik-Unterricht das biologische Geschlecht als Beispiel f√ºr eine zweiwertige kategoriale Variable heranzuziehen. Dazu ein Artikel aus unverd√§chtiger Quelle: Viele Geschlechter? Das ist Unfug!\nOb die extremen Anstrengungen f√ºr die so genannte Gleichstellung am Ende wirklich zielf√ºhrend sind, wage ich doch sehr stark zu bezweifeln. So haben z.B. L√§nder mit hohem Gleichstellungsaufwand eine tieferen Frauen-Anteil an MINT Hochschul-Abschl√ºssen als L√§nder, die doch eher nicht als sehr matriarchalisch gelten. Trotz massiven Anstrengungen dr√§ngen Frauen in Skandinavien wieder mehr in klassische Frauenberufe. Das sollte uns zu denken geben.\n\n\nGender-Equality Paradox in Science, Technology, Engineering and Mathematics. See Stoet and Geary, 2018. See also corrigendum, 2019, and reply to Richardson et al., 2020.\n\n\n\nIn Frankreich hat die Acad√©mie fran√ßaise erkl√§rt, das Gendern sei zur Verfolgung der damit bezweckten gesellschaftspolitischen Ziele (Gleichstellung) untauglich und kontraproduktiv. Der franz√∂sische Bildungsminister hat die Verwendung geschlechtsneutraler Schriftsprache an Schulen per Erlass verboten.\nViele lesenswerte Texte zum Thema findet man unter Gendersterntaler und LinguistikUndGendern."
  },
  {
    "objectID": "posts/shinytest/index.html",
    "href": "posts/shinytest/index.html",
    "title": "Shiny test",
    "section": "",
    "text": "Number of bins:"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html",
    "href": "posts/noncollaps/noncollaps.html",
    "title": "Noncollapsibility of the odds ratio",
    "section": "",
    "text": "We simulate data from GLM with non-confounding covariate \\(C\\):\n\nCodeset.seed(3)\nN <- 400\nC <- sort(runif(N,-8,8)) #non-confounding C\nG<-sample(c(0,1),N,replace=TRUE)\nbeta0<-0\nbeta1<-log(10)\nbeta2<-1\n##Logistic \netai<-beta0+beta1*G+beta2*C\npii<-exp(etai)/(1+exp(etai))\nYdich <-rbinom(G,size=1,prob=pii)\ndat<-data.frame(C,G,Ydich)\ncor(dat)\n\n             C        G  Ydich\nC     1.000000 0.006606 0.8131\nG     0.006606 1.000000 0.1560\nYdich 0.813133 0.156035 1.0000\n\n\n\nCodemodC<-glm(Ydich~G+C,family=\"binomial\")\nmodM<-glm(Ydich~G,family=\"binomial\")\n\n\n\n\nCodepred<-predict(modM,type=\"response\",se.fit=TRUE)\npredgA<-predict(modC,newdata=data.frame(C=C[G==0],G=0),se.fit=TRUE,type=\"response\")\npredgB<-predict(modC,newdata=data.frame(C=C[G==1],G=1),se.fit=TRUE,type=\"response\")\nplot(C,Ydich,col=c(\"blue\",\"red\")[G+1],ylab=\"Probability\")\nlines(sort(C[G==0]),sort(predgA$fit),col=\"blue\")\nlines(sort(C[G==1]),sort(predgB$fit),col=\"red\")\nabline(a=mean(pii[G==0]),b=0,col=\"blue\",lty=2)\nabline(a=mean(pii[G==1]),b=0,col=\"red\",lty=2)\n\n\n\n\n\n\nCodesummary(modM)$coef\n\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept) -0.08004     0.1415 -0.5655 0.571710\nG            0.63377     0.2040  3.1071 0.001889\n\n\n\nEffect of \\(G\\) is larger, even though \\(C\\) is not a confounder. This is due to non-collapsibility of the odds ratio\n\nCodesummary(modC)$coef\n\n            Estimate Std. Error z value  Pr(>|z|)\n(Intercept) -0.05395     0.3208 -0.1682 8.665e-01\nG            2.46270     0.5209  4.7280 2.267e-06\nC            1.04913     0.1200  8.7453 2.223e-18\n\n\n\nEstimate inverse probability weights to fit marginal structural models in a point treatment situation.\n\n\nCodelibrary(ipw)\ntemp <- ipwpoint(exposure=G,family = \"binomial\",link = \"logit\",data=dat,numerator =~1,denominator = ~ C)\nsummary(temp$ipw.weights)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.989   0.994   1.000   1.000   1.006   1.012 \n\nCodedat$sw<-temp$ipw.weights\n\n\n\nMarginal structural model for the causal effect of \\(X\\) on \\(Y\\) corrected for confounding by \\(C\\) using inverse probability weighting\n\nCodemodW<-glm(Ydich~G,weights=sw,data=dat,family=quasibinomial)\nsummary(modW)$coef\n\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  -0.0683     0.1419 -0.4814 0.630474\nG             0.6117     0.2043  2.9938 0.002927\n\n\n\nCoderequire(\"survey\")\nmsm <- (svyglm(Ydich ~ G, family=\"binomial\",design = svydesign(~ 1, weights =~sw,data = dat)))\nsummary(msm)\n\n\n\n\nCodemodelsummary::modelsummary(models=list(\"marginal\"=modM,\"conditional\"=modC,\"IPW\"=modW))\n\n\n\n\n   \n    marginal \n    conditional \n    ¬†IPW \n  \n\n\n (Intercept) \n    ‚àí0.080 \n    ‚àí0.054 \n    ‚àí0.068 \n  \n\n  \n    (0.142) \n    (0.321) \n    (0.142) \n  \n\n G \n    0.634 \n    2.463 \n    0.612 \n  \n\n  \n    (0.204) \n    (0.521) \n    (0.204) \n  \n\n C \n     \n    1.049 \n     \n  \n\n  \n     \n    (0.120) \n     \n  \n\n Num.Obs. \n    400 \n    400 \n    400 \n  \n\n AIC \n    543.4 \n    152.6 \n     \n  \n\n BIC \n    551.4 \n    164.5 \n     \n  \n\n Log.Lik. \n    ‚àí269.718 \n    ‚àí73.275 \n     \n  \n\n F \n    9.654 \n    38.281 \n    8.963 \n  \n\n RMSE \n    0.49 \n    0.23 \n    0.49 \n  \n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nconditional-marginal=noncollaps+confouding\nIPW-marginal=confounding\nconditional-IPW=noncollaps"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#simulate-some-data",
    "href": "posts/noncollaps/noncollaps.html#simulate-some-data",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Simulate some data",
    "text": "Simulate some data\n\nCodelibrary(simstudy)\n# define the data\ndefB <- defData(varname = \"L\", formula =0.27, \n                dist = \"binary\")\ndefB <- defData(defB, varname = \"Y0\", formula = \"-2.5 + 1.75*L\", \n                dist = \"binary\", link = \"logit\")\ndefB <- defData(defB, varname = \"Y1\", formula = \"-1.5 + 1.75*L\", \n                dist = \"binary\", link = \"logit\")\ndefB <- defData(defB, varname = \"A\", formula = \"0.315 + 0.352 * L\", \n                dist = \"binary\")\ndefB <- defData(defB, varname = \"Y\", formula = \"Y0 + A * (Y1 - Y0)\", \n                dist = \"nonrandom\")\ndefB\n\n   varname            formula variance      dist     link\n1:       L               0.27        0    binary identity\n2:      Y0      -2.5 + 1.75*L        0    binary    logit\n3:      Y1      -1.5 + 1.75*L        0    binary    logit\n4:       A  0.315 + 0.352 * L        0    binary identity\n5:       Y Y0 + A * (Y1 - Y0)        0 nonrandom identity\n\n\n\nCodeset.seed(2002)\nNnew<-1000\ndtB <- genData(Nnew, defB)\ndtB\n\n        id L Y0 Y1 A Y\n   1:    1 0  0  0 0 0\n   2:    2 0  0  1 0 0\n   3:    3 1  0  0 1 0\n   4:    4 0  0  0 0 0\n   5:    5 1  1  1 0 1\n  ---                 \n 996:  996 0  0  1 0 0\n 997:  997 0  0  0 1 0\n 998:  998 1  0  1 1 1\n 999:  999 0  0  0 0 0\n1000: 1000 1  0  0 1 0"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#true-causal-effect-based-on-potential-outcomes",
    "href": "posts/noncollaps/noncollaps.html#true-causal-effect-based-on-potential-outcomes",
    "title": "Noncollapsibility of the odds ratio",
    "section": "True causal effect (based on potential outcomes)",
    "text": "True causal effect (based on potential outcomes)\n\nCodeodds <- function (p) {\n    return((p/(1 - p)))\n}\n\ndtB[, log( odds( mean(Y1) ) / odds( mean(Y0) ) )]\n\n[1] 0.9494"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#conditional-effect",
    "href": "posts/noncollaps/noncollaps.html#conditional-effect",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Conditional effect",
    "text": "Conditional effect\nThe true conditional causal effect of \\(A\\) is 1.\n\nCodemc<-glm(Y ~ A + L , data = dtB, family=\"binomial\")\nmc\n\n\nCall:  glm(formula = Y ~ A + L, family = \"binomial\", data = dtB)\n\nCoefficients:\n(Intercept)            A            L  \n      -2.74         1.21         1.61  \n\nDegrees of Freedom: 999 Total (i.e. Null);  997 Residual\nNull Deviance:      964 \nResidual Deviance: 797  AIC: 803\n\n\nThis estimate for \\(A\\) is a good estimate of the conditional effect in the population, based on the potential outcomes at each level of \\(L\\)\n\nCodedtB[, .(LOR = log( odds( mean(Y1) ) / odds( mean(Y0) ) ) ), keyby = L]\n\n   L   LOR\n1: 0 1.104\n2: 1 1.067"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#marginal-effect",
    "href": "posts/noncollaps/noncollaps.html#marginal-effect",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Marginal effect",
    "text": "Marginal effect\nThe marginal estimate is biased both for the conditional effect and the marginal causal effect.\n\nCodemm<-glm(Y ~ A , data = dtB, family=\"binomial\")\nmm\n\n\nCall:  glm(formula = Y ~ A, family = \"binomial\", data = dtB)\n\nCoefficients:\n(Intercept)            A  \n      -2.33         1.59  \n\nDegrees of Freedom: 999 Total (i.e. Null);  998 Residual\nNull Deviance:      964 \nResidual Deviance: 876  AIC: 880"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#numerator-and-denominator-model",
    "href": "posts/noncollaps/noncollaps.html#numerator-and-denominator-model",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Numerator and Denominator model",
    "text": "Numerator and Denominator model\n\nCodenumModel <- glm(A ~ 1, data = dtB, family = \"binomial\")\ndenModel <- glm(A ~ L, data = dtB, family = \"binomial\")"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#stabilized-weights-by-hand",
    "href": "posts/noncollaps/noncollaps.html#stabilized-weights-by-hand",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Stabilized weights by hand",
    "text": "Stabilized weights by hand\n\nCodedtB[, pA0 := predict(numModel, type = \"response\")]\ndtB[, pA := predict(denModel, type = \"response\")]\ndefB2 <- defDataAdd(varname = \"IPW\", \n                    formula = \"(A*pA0+(1-A)*(1-pA0))/((A * pA) + ((1 - A) * (1 - pA)))\", \n                    dist = \"nonrandom\")\ndtB <- addColumns(defB2, dtB)\ndtB[1:6]\n\n   id L Y0 Y1 A Y   pA0     pA    IPW\n1:  1 0  0  0 0 0 0.423 0.3347 0.8673\n2:  2 0  0  1 0 0 0.423 0.3347 0.8673\n3:  3 1  0  0 1 0 0.423 0.6718 0.6297\n4:  4 0  0  0 0 0 0.423 0.3347 0.8673\n5:  5 1  1  1 0 1 0.423 0.6718 1.7578\n6:  6 1  0  0 1 0 0.423 0.6718 0.6297\n\n\n\nCodeunique(dtB$IPW)\n\n[1] 0.8673 0.6297 1.7578 1.2639"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#stabilized-weights-with-ipw-package",
    "href": "posts/noncollaps/noncollaps.html#stabilized-weights-with-ipw-package",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Stabilized weights with ipw package",
    "text": "Stabilized weights with ipw package\n\nCodetempsw<-ipw::ipwpoint(exposure=A,family=\"binomial\",link=\"logit\",numerator=~1,denominator = ~L,data=dtB)\ntempw<-ipw::ipwpoint(exposure=A,family=\"binomial\",link=\"logit\",denominator = ~L,data=dtB)\nunique(tempsw$ipw.weights)\n\n[1] 0.8673 0.6297 1.7578 1.2639\n\nCodemean(tempsw$ipw.weights)\n\n[1] 1\n\nCodeunique(tempw$ipw.weights)\n\n[1] 1.503 1.489 3.047 2.988\n\nCodemean(tempw$ipw.weights)\n\n[1] 2"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#applying-ipw",
    "href": "posts/noncollaps/noncollaps.html#applying-ipw",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Applying IPW",
    "text": "Applying IPW\nUnstabilized weights\n\nCodesummary(mw<-glm(Y ~ A , data = dtB, family=\"binomial\", weights = tempw$ipw.weights))$coef\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n            Estimate Std. Error z value  Pr(>|z|)\n(Intercept)   -2.069     0.1002 -20.645 1.076e-94\nA              1.081     0.1229   8.801 1.354e-18\n\n\nStabilized weights\n\nCodesummary(mws<-glm(Y ~ A , data = dtB, family=\"binomial\", weights = tempsw$ipw.weights))$coef\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n            Estimate Std. Error z value  Pr(>|z|)\n(Intercept)   -2.069     0.1319 -15.682 1.996e-55\nA              1.081     0.1713   6.312 2.760e-10"
  },
  {
    "objectID": "posts/noncollaps/noncollaps.html#comparison-1",
    "href": "posts/noncollaps/noncollaps.html#comparison-1",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Comparison",
    "text": "Comparison\n\nCodemodelsummary::modelsummary(models=list(\"marginal\"=mm,\"conditional\"=mc,\"IPW\"=mw,\"IPWs\"=mws))\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n\n\n\n   \n    marginal \n    conditional \n    ¬†IPW \n    ¬†IPWs \n  \n\n\n (Intercept) \n    ‚àí2.333 \n    ‚àí2.736 \n    ‚àí2.069 \n    ‚àí2.069 \n  \n\n  \n    (0.147) \n    (0.165) \n    (0.100) \n    (0.132) \n  \n\n A \n    1.587 \n    1.211 \n    1.081 \n    1.081 \n  \n\n  \n    (0.180) \n    (0.191) \n    (0.123) \n    (0.171) \n  \n\n L \n     \n    1.614 \n     \n     \n  \n\n  \n     \n    (0.183) \n     \n     \n  \n\n Num.Obs. \n    1000 \n    1000 \n    1000 \n    1000 \n  \n\n AIC \n    880.1 \n    802.5 \n    1847.3 \n    1004.4 \n  \n\n BIC \n    889.9 \n    817.3 \n    1857.1 \n    1014.2 \n  \n\n Log.Lik. \n    ‚àí438.049 \n    ‚àí398.272 \n    ‚àí921.632 \n    ‚àí500.206 \n  \n\n F \n    77.828 \n    71.500 \n    77.460 \n    39.837 \n  \n\n RMSE \n    0.37 \n    0.35 \n    0.37 \n    0.37 \n  \n\n\n\n\n\n\nWe used R version 4.3.2 [@base] and the following R packages: ipw v. 1.2 [@ipw], rio v. 0.5.26 [@rio], simstudy v. 0.7.1 [@simstudy].\n\n\n   Package Version  Citation\n1     base   4.3.2     @base\n2      ipw     1.2      @ipw\n3      rio  0.5.26      @rio\n4 simstudy   0.7.1 @simstudy"
  },
  {
    "objectID": "posts/noncollaps/index.html",
    "href": "posts/noncollaps/index.html",
    "title": "Noncollapsibility of the odds ratio",
    "section": "",
    "text": "We simulate data from GLM with non-confounding covariate \\(C\\):\n\nset.seed(3)\nN <- 400\nC <- sort(runif(N,-8,8)) #non-confounding C\nG<-sample(c(0,1),N,replace=TRUE)\nbeta0<-0\nbeta1<-log(10)\nbeta2<-1\n##Logistic \netai<-beta0+beta1*G+beta2*C\npii<-exp(etai)/(1+exp(etai))\nYdich <-rbinom(G,size=1,prob=pii)\ndat<-data.frame(C,G,Ydich)\ncor(dat)\n\n             C        G  Ydich\nC     1.000000 0.006606 0.8131\nG     0.006606 1.000000 0.1560\nYdich 0.813133 0.156035 1.0000\n\n\n\nmodC<-glm(Ydich~G+C,family=\"binomial\")\nmodM<-glm(Ydich~G,family=\"binomial\")\n\n\n\npred<-predict(modM,type=\"response\",se.fit=TRUE)\npredgA<-predict(modC,newdata=data.frame(C=C[G==0],G=0),se.fit=TRUE,type=\"response\")\npredgB<-predict(modC,newdata=data.frame(C=C[G==1],G=1),se.fit=TRUE,type=\"response\")\nplot(C,Ydich,col=c(\"blue\",\"red\")[G+1],ylab=\"Probability\")\nlines(sort(C[G==0]),sort(predgA$fit),col=\"blue\")\nlines(sort(C[G==1]),sort(predgB$fit),col=\"red\")\nabline(a=mean(pii[G==0]),b=0,col=\"blue\",lty=2)\nabline(a=mean(pii[G==1]),b=0,col=\"red\",lty=2)\n\n\n\n\n\n\nsummary(modM)$coef\n\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept) -0.08004     0.1415 -0.5655 0.571710\nG            0.63377     0.2040  3.1071 0.001889\n\n\n\nEffect of \\(G\\) is larger, even though \\(C\\) is not a confounder. This is due to non-collapsibility of the odds ratio\n\nsummary(modC)$coef\n\n            Estimate Std. Error z value  Pr(>|z|)\n(Intercept) -0.05395     0.3208 -0.1682 8.665e-01\nG            2.46270     0.5209  4.7280 2.267e-06\nC            1.04913     0.1200  8.7453 2.223e-18\n\n\n\nEstimate inverse probability weights to fit marginal structural models in a point treatment situation.\n\n\nlibrary(ipw)\ntemp <- ipwpoint(exposure=G,family = \"binomial\",link = \"logit\",data=dat,numerator =~1,denominator = ~ C)\nsummary(temp$ipw.weights)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.989   0.994   1.000   1.000   1.006   1.012 \n\ndat$sw<-temp$ipw.weights\n\n\nMarginal structural model for the causal effect of \\(X\\) on \\(Y\\) corrected for confounding by \\(C\\) using inverse probability weighting\n\nmodW<-glm(Ydich~G,weights=sw,data=dat,family=quasibinomial)\nsummary(modW)$coef\n\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  -0.0683     0.1419 -0.4814 0.630474\nG             0.6117     0.2043  2.9938 0.002927\n\n\n\nrequire(\"survey\")\nmsm <- (svyglm(Ydich ~ G, family=\"binomial\",design = svydesign(~ 1, weights =~sw,data = dat)))\nsummary(msm)\n\n\n\nmodelsummary::modelsummary(models=list(\"marginal\"=modM,\"conditional\"=modC,\"IPW\"=modW))\n\n\n\n\n   \n    marginal \n    conditional \n    ¬†IPW \n  \n\n\n (Intercept) \n    ‚àí0.080 \n    ‚àí0.054 \n    ‚àí0.068 \n  \n\n  \n    (0.142) \n    (0.321) \n    (0.142) \n  \n\n G \n    0.634 \n    2.463 \n    0.612 \n  \n\n  \n    (0.204) \n    (0.521) \n    (0.204) \n  \n\n C \n     \n    1.049 \n     \n  \n\n  \n     \n    (0.120) \n     \n  \n\n Num.Obs. \n    400 \n    400 \n    400 \n  \n\n AIC \n    543.4 \n    152.6 \n     \n  \n\n BIC \n    551.4 \n    164.5 \n     \n  \n\n Log.Lik. \n    ‚àí269.718 \n    ‚àí73.275 \n     \n  \n\n F \n    9.654 \n    38.281 \n    8.963 \n  \n\n RMSE \n    0.49 \n    0.23 \n    0.49 \n  \n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nconditional-marginal=noncollaps+confouding\nIPW-marginal=confounding\nconditional-IPW=noncollaps"
  },
  {
    "objectID": "posts/noncollaps/index.html#simulate-some-data",
    "href": "posts/noncollaps/index.html#simulate-some-data",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Simulate some data",
    "text": "Simulate some data\n\nlibrary(simstudy)\n# define the data\ndefB <- defData(varname = \"L\", formula =0.27, \n                dist = \"binary\")\ndefB <- defData(defB, varname = \"Y0\", formula = \"-2.5 + 1.75*L\", \n                dist = \"binary\", link = \"logit\")\ndefB <- defData(defB, varname = \"Y1\", formula = \"-1.5 + 1.75*L\", \n                dist = \"binary\", link = \"logit\")\ndefB <- defData(defB, varname = \"A\", formula = \"0.315 + 0.352 * L\", \n                dist = \"binary\")\ndefB <- defData(defB, varname = \"Y\", formula = \"Y0 + A * (Y1 - Y0)\", \n                dist = \"nonrandom\")\ndefB\n\n   varname            formula variance      dist     link\n1:       L               0.27        0    binary identity\n2:      Y0      -2.5 + 1.75*L        0    binary    logit\n3:      Y1      -1.5 + 1.75*L        0    binary    logit\n4:       A  0.315 + 0.352 * L        0    binary identity\n5:       Y Y0 + A * (Y1 - Y0)        0 nonrandom identity\n\n\n\nset.seed(2002)\nNnew<-1000\ndtB <- genData(Nnew, defB)\ndtB\n\n        id L Y0 Y1 A Y\n   1:    1 0  0  0 0 0\n   2:    2 0  0  1 0 0\n   3:    3 1  0  0 1 0\n   4:    4 0  0  0 0 0\n   5:    5 1  1  1 0 1\n  ---                 \n 996:  996 0  0  1 0 0\n 997:  997 0  0  0 1 0\n 998:  998 1  0  1 1 1\n 999:  999 0  0  0 0 0\n1000: 1000 1  0  0 1 0"
  },
  {
    "objectID": "posts/noncollaps/index.html#true-causal-effect-based-on-potential-outcomes",
    "href": "posts/noncollaps/index.html#true-causal-effect-based-on-potential-outcomes",
    "title": "Noncollapsibility of the odds ratio",
    "section": "True causal effect (based on potential outcomes)",
    "text": "True causal effect (based on potential outcomes)\n\nodds <- function (p) {\n    return((p/(1 - p)))\n}\n\ndtB[, log( odds( mean(Y1) ) / odds( mean(Y0) ) )]\n\n[1] 0.9494"
  },
  {
    "objectID": "posts/noncollaps/index.html#conditional-effect",
    "href": "posts/noncollaps/index.html#conditional-effect",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Conditional effect",
    "text": "Conditional effect\nThe true conditional causal effect of \\(A\\) is 1.\n\nmc<-glm(Y ~ A + L , data = dtB, family=\"binomial\")\nmc\n\n\nCall:  glm(formula = Y ~ A + L, family = \"binomial\", data = dtB)\n\nCoefficients:\n(Intercept)            A            L  \n      -2.74         1.21         1.61  \n\nDegrees of Freedom: 999 Total (i.e. Null);  997 Residual\nNull Deviance:      964 \nResidual Deviance: 797  AIC: 803\n\n\nThis estimate for \\(A\\) is a good estimate of the conditional effect in the population, based on the potential outcomes at each level of \\(L\\)\n\ndtB[, .(LOR = log( odds( mean(Y1) ) / odds( mean(Y0) ) ) ), keyby = L]\n\n   L   LOR\n1: 0 1.104\n2: 1 1.067"
  },
  {
    "objectID": "posts/noncollaps/index.html#marginal-effect",
    "href": "posts/noncollaps/index.html#marginal-effect",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Marginal effect",
    "text": "Marginal effect\nThe marginal estimate is biased both for the conditional effect and the marginal causal effect.\n\nmm<-glm(Y ~ A , data = dtB, family=\"binomial\")\nmm\n\n\nCall:  glm(formula = Y ~ A, family = \"binomial\", data = dtB)\n\nCoefficients:\n(Intercept)            A  \n      -2.33         1.59  \n\nDegrees of Freedom: 999 Total (i.e. Null);  998 Residual\nNull Deviance:      964 \nResidual Deviance: 876  AIC: 880"
  },
  {
    "objectID": "posts/noncollaps/index.html#numerator-and-denominator-model",
    "href": "posts/noncollaps/index.html#numerator-and-denominator-model",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Numerator and Denominator model",
    "text": "Numerator and Denominator model\n\nnumModel <- glm(A ~ 1, data = dtB, family = \"binomial\")\ndenModel <- glm(A ~ L, data = dtB, family = \"binomial\")"
  },
  {
    "objectID": "posts/noncollaps/index.html#stabilized-weights-by-hand",
    "href": "posts/noncollaps/index.html#stabilized-weights-by-hand",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Stabilized weights by hand",
    "text": "Stabilized weights by hand\n\ndtB[, pA0 := predict(numModel, type = \"response\")]\ndtB[, pA := predict(denModel, type = \"response\")]\ndefB2 <- defDataAdd(varname = \"IPW\", \n                    formula = \"(A*pA0+(1-A)*(1-pA0))/((A * pA) + ((1 - A) * (1 - pA)))\", \n                    dist = \"nonrandom\")\ndtB <- addColumns(defB2, dtB)\ndtB[1:6]\n\n   id L Y0 Y1 A Y   pA0     pA    IPW\n1:  1 0  0  0 0 0 0.423 0.3347 0.8673\n2:  2 0  0  1 0 0 0.423 0.3347 0.8673\n3:  3 1  0  0 1 0 0.423 0.6718 0.6297\n4:  4 0  0  0 0 0 0.423 0.3347 0.8673\n5:  5 1  1  1 0 1 0.423 0.6718 1.7578\n6:  6 1  0  0 1 0 0.423 0.6718 0.6297\n\n\n\nunique(dtB$IPW)\n\n[1] 0.8673 0.6297 1.7578 1.2639"
  },
  {
    "objectID": "posts/noncollaps/index.html#stabilized-weights-with-ipw-package",
    "href": "posts/noncollaps/index.html#stabilized-weights-with-ipw-package",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Stabilized weights with ipw package",
    "text": "Stabilized weights with ipw package\n\ntempsw<-ipw::ipwpoint(exposure=A,family=\"binomial\",link=\"logit\",numerator=~1,denominator = ~L,data=dtB)\ntempw<-ipw::ipwpoint(exposure=A,family=\"binomial\",link=\"logit\",denominator = ~L,data=dtB)\nunique(tempsw$ipw.weights)\n\n[1] 0.8673 0.6297 1.7578 1.2639\n\nmean(tempsw$ipw.weights)\n\n[1] 1\n\nunique(tempw$ipw.weights)\n\n[1] 1.503 1.489 3.047 2.988\n\nmean(tempw$ipw.weights)\n\n[1] 2"
  },
  {
    "objectID": "posts/noncollaps/index.html#applying-ipw",
    "href": "posts/noncollaps/index.html#applying-ipw",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Applying IPW",
    "text": "Applying IPW\nUnstabilized weights\n\nsummary(mw<-glm(Y ~ A , data = dtB, family=\"binomial\", weights = tempw$ipw.weights))$coef\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n            Estimate Std. Error z value  Pr(>|z|)\n(Intercept)   -2.069     0.1002 -20.645 1.076e-94\nA              1.081     0.1229   8.801 1.354e-18\n\n\nStabilized weights\n\nsummary(mws<-glm(Y ~ A , data = dtB, family=\"binomial\", weights = tempsw$ipw.weights))$coef\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n            Estimate Std. Error z value  Pr(>|z|)\n(Intercept)   -2.069     0.1319 -15.682 1.996e-55\nA              1.081     0.1713   6.312 2.760e-10"
  },
  {
    "objectID": "posts/noncollaps/index.html#comparison-1",
    "href": "posts/noncollaps/index.html#comparison-1",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Comparison",
    "text": "Comparison\n\nmodelsummary::modelsummary(models=list(\"marginal\"=mm,\"conditional\"=mc,\"IPW\"=mw,\"IPWs\"=mws))\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n\n\n\n   \n    marginal \n    conditional \n    ¬†IPW \n    ¬†IPWs \n  \n\n\n (Intercept) \n    ‚àí2.333 \n    ‚àí2.736 \n    ‚àí2.069 \n    ‚àí2.069 \n  \n\n  \n    (0.147) \n    (0.165) \n    (0.100) \n    (0.132) \n  \n\n A \n    1.587 \n    1.211 \n    1.081 \n    1.081 \n  \n\n  \n    (0.180) \n    (0.191) \n    (0.123) \n    (0.171) \n  \n\n L \n     \n    1.614 \n     \n     \n  \n\n  \n     \n    (0.183) \n     \n     \n  \n\n Num.Obs. \n    1000 \n    1000 \n    1000 \n    1000 \n  \n\n AIC \n    880.1 \n    802.5 \n    1847.3 \n    1004.4 \n  \n\n BIC \n    889.9 \n    817.3 \n    1857.1 \n    1014.2 \n  \n\n Log.Lik. \n    ‚àí438.049 \n    ‚àí398.272 \n    ‚àí921.632 \n    ‚àí500.206 \n  \n\n F \n    77.828 \n    71.500 \n    77.460 \n    39.837 \n  \n\n RMSE \n    0.37 \n    0.35 \n    0.37 \n    0.37 \n  \n\n\n\n\n\n\nWe used R version 4.3.2 (R Core Team 2023) and the following R packages: ipw v. 1.2 (van der Wal and Geskus 2011), rio v. 0.5.26 (Chan et al. 2021), simstudy v. 0.7.1 (Goldfeld and Wujciak-Jens 2020).\n\n\n   Package Version  Citation\n1     base   4.3.2     @base\n2      ipw     1.2      @ipw\n3      rio  0.5.26      @rio\n4 simstudy   0.7.1 @simstudy"
  }
]