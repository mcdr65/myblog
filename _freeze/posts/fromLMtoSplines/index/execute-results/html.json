{
  "hash": "b40942008744d668ec7560af44019f1e",
  "result": {
    "markdown": "---\ntitle: \"Beyond linearity\"\ndate: \"2022-10-06\"\ndescription: \"From linear model to GAM\"\ncategories: [code, analysis]\nfig-cap-location: top\n---\n\n\n\n\n# Data\n\nTriceps skinfold thickness dataset: The data are derived from an anthropometric study of 892 females under 50 years in three Gambian villages in West Africa.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MultiKink)\nlibrary(ggplot2)\nlibrary(psych)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'psych'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"triceps\")\nheadTail(triceps)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      age lntriceps triceps\n1   12.05      1.22     3.4\n2    9.91      1.39       4\n3   10.04      1.44     4.2\n4   11.49      1.44     4.2\n...   ...       ...     ...\n889  7.91      1.92     6.8\n890  7.99      1.44     4.2\n891 14.63       2.2       9\n892 30.14       2.1     8.2\n```\n:::\n\n```{.r .cell-code}\ntri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\n# Polynomial regression\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.cubic.poly <- lm(triceps~poly(age,3,raw=TRUE),data=triceps)\n## the same model:\n## model.cubic <- lm(triceps~age + I(age^2) + I(age^3),\n##                   data=triceps)\ntri.age.plot + \n   stat_smooth(method = \"lm\", \n               formula = y~poly(x,3,raw=T), size = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/polynomial-1.png){width=672}\n:::\n:::\n\n\n\n\n# Cross-validation of different polynomials\n\n## RMSE for quadratic\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n```\n:::\n\n```{.r .cell-code}\nset.seed(1234)\ntrC.lm <- trainControl(method = \"repeatedcv\", \n                       number = 10,         \n                       repeats = 10)        \npol.model <- train(triceps ~ poly(age,3),\n                       data = triceps, \n                       method = \"lm\",\n                       trControl = trC.lm)    \npol.model$results[2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      RMSE\n1 3.865866\n```\n:::\n:::\n\n\n## RMSE for different degrees\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy.pol.f <- function(x){\n    xx<-poly(triceps$age, x, raw=T)    \n    new.data  <- cbind(triceps=triceps$triceps, xx)                                 \n    pol.model <- train(triceps~., data = new.data,method = \"lm\")    \n    RMSE.cv = pol.model$results[2]\n  }\n\nt(sapply(1:10, my.pol.f))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     RMSE     RMSE     RMSE     RMSE    RMSE     RMSE     RMSE     RMSE     RMSE     RMSE    \n[1,] 3.984711 4.083302 3.830449 3.77627 3.787051 3.740982 3.847184 3.803367 3.866925 3.803712\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntri.age.plot + \n   stat_smooth(method = \"lm\", \n               formula = y~poly(x,6,raw=T), size = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n# Piecewise linear regression\n\nInstead of fitting a high-degree polynomial over the entire range of $X$, piecewise polynomial regression involves fitting separate low-degree polynomials\nover different regions of $X$. For example, a piecewise cubic polynomial works\nby fitting a cubic regression model of the form \n\n$$Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3x_i^3+\\epsilon_i,$$ \n\nwhere the coefficients differ in different parts of the range of $X$. The points where the coefficients change are called *knots* $\\xi_k$, $k=1,\\dots,K$.\n\nLet us begin with a piecewise linear (degree=1):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred1 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age<5,]))\npred2 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age >=5 & triceps$age<10,]))\npred3 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=10 & triceps$age<20,]))\npred4 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=20 & triceps$age<30,]))\npred5 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=30 & triceps$age<40,]))\npred6 <- predict(lm(triceps~age, \n                    data = triceps[triceps$age>=40,]))\ntri.age.plot + \n  geom_line(data=triceps[triceps$age<5,], \n            aes(y = pred1, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age >=5 & triceps$age<10,], \n            aes(y = pred2, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=10 & triceps$age<20,], \n            aes(y = pred3, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=20 & triceps$age<30,], \n            aes(y = pred4, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=30 & triceps$age<40,], \n            aes(y = pred5, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age>=40,], \n            aes(y = pred6, x=age), size = 1, col=\"blue\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Continuous piecewise linear regression\n\nWe want a continuous function. Let us define a *truncated power basis function* per knot $\\xi$,\n\n$$h(x, \\xi)=(x-\\xi)_{+}=\n\\begin{cases}\n  x-\\xi, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else}.\n\\end{cases}\n$$ \n\nThe continuous piecewise regression equation is\n\n$$Y_i=\\beta_0+\\beta_1x_i+\\beta_2 h(x_i,5)+\\cdots+\\beta_6 h(x_i,40) + \\epsilon_i$$\n\n\nThis can be done -by hand- or with B-splines `splines::bs()`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred7 <- predict(lm(triceps~ age + I((age-5)*(age>=5)) +\n                                   I((age-10)*(age >= 10)) +\n                                   I((age-20)*(age >= 20)) +\n                                   I((age-30)*(age >= 30)) +\n                                  I((age-40)*(age >= 40)),\n                    data = triceps))\nlibrary(splines)\npred.lm.bs <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred7+.2, x=age), size = 1, col=\"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n<!-- ## Piecewise quadratic polynomial -->\n\n\n\n\n\n\n\n\n# Splines\n\n## Quadratic spline\n\nWith \n\n$$h(x, \\xi)=(x-\\xi)_{+}^2=\n\\begin{cases}\n  (x-\\xi)^2, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n$$\n\nwe have as regression equation \n$$Y_i=\\beta_0+\\beta_1x_i+\\beta_2x^2+\\beta_3 h(x_i,5)+\\cdots+\\beta_7 h(x_i,40) + \\epsilon_i$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred.quadsmooth <- predict(lm(triceps~ age + I(age^2) + \n                    I((age-5)^2*(age>=5)) +\n                    I((age-10)^2*(age>=10)) +\n                    I((age-20)^2*(age>=20)) +\n                    I((age-30)^2*(age>=30)) +\n                    I((age-40)^2*(age>=40)),\n                    data = triceps))\npred.quadsmooth2 <- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=2), data=triceps))                        \ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth2+.2, x=age), size = 1, col=\"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n## Cubic Spline\n\nMost often, cubic splines are used. Adding the following truncated power basis function per knot,\n\n$$h(x, \\xi)=(x-\\xi)_{+}^3=\n\\begin{cases}\n  (x-\\xi)^3, \\text{\\,if\\,} x>\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n$$\n\n\nto the model for a cubic polynomial will lead to a discontinuity in\n*only the third derivative* at $\\xi$; the function will remain continuous, with\n*continuous first and second derivatives, at each of the knots*:\n\n$$Y_i=\\beta_0+\\beta_1x_i+\\beta_2x^2+\\beta_3x^3+\\beta_4h(x_i,5)+\\cdots+\\beta_8h(x_i,40)^3 + \\epsilon_i$$\n\nOne can show that a cubic spline has $K+4$ parameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncub.splines.bs <- lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree = 3), data=triceps)\n```\n:::\n\n\n## Natural splines\n\nNatural splines have an additional restriction that the fitted curve *linear at the extremes*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntri.age.plot <- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot +\n    stat_smooth(method = \"lm\", \n               formula = y~bs(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"green\") + \n    stat_smooth(method = \"lm\", \n               formula = y~ns(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"red\")\n```\n\n::: {.cell-output-display}\n![polynomial cubic splines (green), natural cubic splines (red)](index_files/figure-html/ns-1.png){width=672}\n:::\n:::\n\n\n\n# Smoothing splines\n\nAvoids the knot selection problem completely by using a maximal set of\nknots. The complexity of the fit is controlled by regularization.\nProblem: among all functions $f(x)$ with two continuous derivatives,\nfind one that minimizes the penalized residual sum of squares\n\n$$ RSS(f,\\lambda)=\\sum_{i=1}^N(y_i-f(x_i))^2+\\lambda[f''(t)]^2dt$$\n\nwhere $\\lambda$ is a fixed smoothing parameter. The first term measures closeness to the data, while the second term\npenalizes curvature in the function, and $\\lambda$ establishes a tradeoff\nbetween the two. Special cases: $\\lambda=0$ (no constraint on $f$) and\n$\\lambda=\\infty$ ($f$ has to be linear). It can be shown that this\nproblem has an explicit, finite-dimensional, unique minimizer which is\na natural cubic spline with knots at the unique values of the $x_i,i= 1, . . . , N.$\n\nAt face value it seems that the family is still over-parametrized, since\nthere are as many as $N$ knots, which implies $N$ degrees of freedom.\nHowever, the penalty term translates to a penalty on the spline\ncoefficients, which are shrunk some of the way toward the linear fit.\n\nThe solution is of the form\n\n$$f(x)=\\sum_{j=1}^N\\theta_iN_j(x),$$\\\n\nwhere the $N_j(x)$ are an $N$-dimensional set of basis functions for\nrepresenting this family of natural splines.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsspline <- smooth.spline(x=triceps$age, y=triceps$triceps, cv=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in smooth.spline(x = triceps$age, y = triceps$triceps, cv = TRUE): cross-validation with non-unique 'x' values\nseems doubtful\n```\n:::\n\n```{.r .cell-code}\nplot(triceps$age, triceps$triceps)\nlines(sspline, lwd=3,col=\"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n# Generalized additive model \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mgcv)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: nlme\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is mgcv 1.8-35. For overview type 'help(\"mgcv-package\")'.\n```\n:::\n\n```{.r .cell-code}\ngamtri<-gam(triceps~s(age,bs=\"cr\"),data=triceps)\nsummary(gamtri)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ntriceps ~ s(age, bs = \"cr\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   9.7024     0.1255   77.29   <2e-16\n\nApproximate significance of smooth terms:\n         edf Ref.df    F p-value\ns(age) 6.706  7.539 85.6  <2e-16\n\nR-sq.(adj) =  0.419   Deviance explained = 42.3%\nGCV =  14.18  Scale est. = 14.057    n = 892\n```\n:::\n\n```{.r .cell-code}\nplot(gamtri)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/GAM-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}