[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Design Matrix for interaction effects\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\nMatrix Algebra\n\n\n\n\n\nFeb 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nNoncollapsibility of the odds ratio\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\nIPW-analysis\n\n\n\n\n\nDec 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCompositions\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\nSimplex as sample space: Tetrahedron for 4-part compositions\n\n\n\n\n\nNov 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nAber der Kaiser hat ja gar nichts an!\n\n\n\n\n\n\nmeinung\n\n\n\nGegen Identit√§tspolitik\n\n\n\n\n\nOct 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond linearity\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\nFrom linear model to GAM\n\n\n\n\n\nOct 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nExponential Growth\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\nexp and log\n\n\n\n\n\nSep 29, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 26, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "üëã Hi, I‚Äôm Andr√© Meichtry\nüëÄ I‚Äôm interested in philosophy, physics, quantitative research methodology and biostatistics.\n‚ù§Ô∏è I like üèÉ."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Welcome!"
  },
  {
    "objectID": "posts/Khatri-Rao-Product/index.html",
    "href": "posts/Khatri-Rao-Product/index.html",
    "title": "Design Matrix for interaction effects",
    "section": "",
    "text": "Problem discussed with Niklaus Meier (Thank you.)\nAssume we want interaction terms of continuous variables (variables in \\(\\mathbf{X}\\)) with categorical variables (variables in \\(\\mathbf{J}\\)). The corresponding Design Matrix is the Transposed Khatri-Rao Product; this is a row-by-row Kronecker product of two matrices.\n\\[\n\\mathbf{J} \\bullet \\mathbf{X}\n=\n\\begin{bmatrix}\n\\mathbf{J}[1,] \\otimes \\mathbf{X}[1,]\\\\\\hline\n\\mathbf{J}[2,] \\otimes \\mathbf{X}[2,]\\\\\\hline\n\\mathbf{J}[3,] \\otimes \\mathbf{X}[3,]\\\\\\hline\n...\\\\\\hline\n\\mathbf{J}[n,] \\otimes \\mathbf{X}[n,]\\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "posts/Khatri-Rao-Product/index.html#design-matrix-for-interaction-effects",
    "href": "posts/Khatri-Rao-Product/index.html#design-matrix-for-interaction-effects",
    "title": "Design Matrix for interaction effects",
    "section": "",
    "text": "Problem discussed with Niklaus Meier (Thank you.)\nAssume we want interaction terms of continuous variables (variables in \\(\\mathbf{X}\\)) with categorical variables (variables in \\(\\mathbf{J}\\)). The corresponding Design Matrix is the Transposed Khatri-Rao Product; this is a row-by-row Kronecker product of two matrices.\n\\[\n\\mathbf{J} \\bullet \\mathbf{X}\n=\n\\begin{bmatrix}\n\\mathbf{J}[1,] \\otimes \\mathbf{X}[1,]\\\\\\hline\n\\mathbf{J}[2,] \\otimes \\mathbf{X}[2,]\\\\\\hline\n\\mathbf{J}[3,] \\otimes \\mathbf{X}[3,]\\\\\\hline\n...\\\\\\hline\n\\mathbf{J}[n,] \\otimes \\mathbf{X}[n,]\\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "posts/logratioGeometry/index.html",
    "href": "posts/logratioGeometry/index.html",
    "title": "Compositions",
    "section": "",
    "text": "Sample space of compositional data\nThe sample space of compositional data with \\(D\\) parts is a simplex \\(\\mathcal{S}^D\\) of dimension \\(D-1\\):\n\\(\\mathcal{S}^D=\\{\\mathbf{x}=[x_1,x_2,\\dots,x_D]\\in \\mathbb{R}^D \\mid\nx_i&gt;0, i=1,2,\\dots,D; \\sum_{i=1}^Dx_i=\\mathcal{k}\\}\\)\nThe only information is given by the ratios between components, so the information of a composition is preserved under multiplication by any positive constant. Therefore, the sample space of compositional data can always be assumed to be a standard simplex, i.e.¬†\\(\\mathcal{k}\n= 1\\).\nNormalization to the standard simplex is called closure and is\n\\(\\mathcal{C}[x_1,x_2,\\dots,x_D]=\\left[\\frac{x_1}{\\sum_{i=1}^D x_i},\\frac{x_2}{\\sum_{i=1}^D x_i}, \\dots,\\frac{x_D}{\\sum_{i=1}^D x_i}\\right]\\)\n\n\nExample\n4 Raters rated a 4-part-composition on \\(n=20\\) subjects. See the interactive Tetrahedron\n\nplot3D(datAitch,col=as.numeric(Rater),size=5,axes=TRUE,coors=TRUE)"
  },
  {
    "objectID": "posts/gendern/index.html",
    "href": "posts/gendern/index.html",
    "title": "Aber der Kaiser hat ja gar nichts an!",
    "section": "",
    "text": "In Zeiten, in denen ‚Äì an vom Steuerzahler finanzierten Hochschulen ‚Äì Sprachleitfaden verteilt werden, scheint es doch wichtig, Gegendruck auch aus der politischen Mitte ‚Äì also nicht nur von der extremen Rechten ‚Äì aufzubauen. Es ist nicht die Aufgabe staatlicher Institutionen, an der Verbreitung von Ideologien mitzuwirken und Vorgaben zu machen, was gute Sprache ist. Sprachpolitik zu betreiben ist aus meiner Sicht etwas vom Schlimmsten, was eine Hochschule machen kann.\nDas grammatikalische bildet nicht das biologische Geschlecht ab. Diese einfache Tatsache wird von der Linguistik der Genderist*innen geleugnet. Wer sich z.B. in der Klimadebatte gleich verhielte wie die Gender-Aktivisten mit der Sprache, w√ºrde sofort (und zurecht) als Wissenschaftsleugner diffamiert. Auch sind die vorgebrachten Assoziationsstudien gegen das generische Maskulinum wenig √ºberzeugend:\n\nUm die mangelnde Eignung des generischen Maskulinums zum inklusiven Formulieren vorzuf√ºhren, wird immer wieder gerne folgende Frage pr√§sentiert: ‚ÄûWer ist dein Lieblingsschauspieler?‚Äú (Stahlberg et al., 2001). Werden auf diese Frage √ºberwiegend m√§nnliche Schauspieler genannt, so werten Bef√ºrworter des Genderns dies als Beleg daf√ºr, dass generische Maskulina vorrangig die Vorstellung von M√§nnern ausl√∂sen. Allerdings ist diese Frage nicht im Geringsten geeignet, die Untauglichkeit des inklusiven Maskulinums zu demonstrieren. Denn diese Frage ist keine typische Verwendung des generischen Maskulinums. W√ºrde man ganz allgemein nach Lieblingsschauspielern fragen, so lautete die korrekte Formulierung ‚ÄûWer/welche sind deine Lieblingsschauspieler?‚Äú (Frage im Plural!). Im Singular w√ºrde man entweder fragen ‚ÄûWer ist deine Lieblingsschauspielerin?‚Äú oder ‚ÄûWer ist dein m√§nnlicher Lieblingsschauspieler?‚Äú Das generische Maskulinum wird bei allgemeinen Aussagen verwendet ‚Äì nicht, wenn konkrete Personen gemeint sind (wie in der Frage nach dem Lieblingsschauspieler).\n\nLetztendlich ist es bei vielen die Angst, als frauenfeindlich (oder feindlich anderen sozialen Geschlechtern gegen√ºber) dazustehen, die es √ºberhaupt erm√∂glicht, dass solche Sprachpolitik an den Hochschulen betrieben werden kann:\n\nVielleicht endet die Geschichte des geschlechtergerechten Sprachumbaus mit all seinen grotesken Ausw√ºchsen eines Tages wie Andersens M√§rchen vom Kaiser und seinen neuen Kleidern. Dort ist es bekanntlich ein Kind, das am Ende ausruft: ‚ÄûAber der Kaiser hat ja gar nichts an!‚Äú und dem Spuk damit ein Ende macht. Zuvor wollte in dem M√§rchen niemand eingestehen, dass er √ºberhaupt keine Kleider sieht, weil er Angst hatte, in diesem Fall f√ºr dumm zu gelten. Beim Gendern ist es unsere Angst, von den anderen f√ºr ‚Äûfrauenfeindlich‚Äú gehalten zu werden oder nicht auf der H√∂he der Zeit zu sein, die viele mitlaufen l√§sst. Dabei ist die geschlechtergerechte Sprache noch nicht einmal ein ‚Äûneues Kleid‚Äú, sondern ein √ºber 40 Jahre altes Konzept, bei dem die Frage erlaubt sein muss, was es heute noch f√ºr ein gleichberechtigtes Miteinander der Geschlechter zu leisten vermag.\n\nF√ºr Tomas Kubelik ist die Sprache unschuldig. Hier ein unterhaltsamer, humorvoller und gut aufgebauter Vortrag. Sein aus meiner Sicht nachvollziehbares Fazit ist:\n\nAlle Formen des Genderns sind unbrauchbar. Sie sind in sich widerspr√ºchlich, sie sind nicht konsequent durchf√ºhrbar, sie stossen an die Grenzen von Logik, Praktikabilit√§t und Akzeptanz. Sie sind un√§sthetisch, un√∂konomisch und irref√ºhrend. (Tomas Kubelik, Vortrag und Text)\n\nF√ºr Ingo Meyer (Das M√§rchen vom Gendersterntaler) ist das Hauptargument gegen das Gendern:\n\nSprache entwickelt sich seit Jahrhunderten. Was funktioniert, setzt sich durch; was die Verst√§ndigung erschwert, wird abgeschliffen. Nie ist es ohne Schaden gelungen, diesen unbewussten Akt nachzuahmen. Zwar stimmt es: Wenn ich die Meldung ‚ÄûSonntagsausfl√ºgler dr√§ngten ins Gr√ºne‚Äú lese, stelle ich mir die Menschen derzeit vorwiegend wei√ü vor. Um diesen Satz f√ºr mich ‚Äûgerechter‚Äú zu machen, br√§uchte ich also vielerlei Hinweise. Gerecht in diesem Sinne w√§re eine Formulierung wie ‚ÄûDie LSBTI+, PoC, alte und junge Menschen inkludierenden Sonntagsausfl√ºgler*innen dr√§ngten ins Gr√ºne‚Äú. Das ist offensichtlich absurd. Sprache hat nicht die Aufgabe, von Dritten erw√ºnschte Bedeutungen in unsere K√∂pfe zu pflanzen. Es gibt keine geschlechtergerechte Sprache. Es gibt √ºberhaupt keine gerechte Sprache. Es steht uns aber frei, die vorhandene Sprache gerecht zu verwenden.\n\nEin einfach und klar geschriebenes Buch ist auch: Fabian Payr: Von Menschen und Mensch*innen. 20 gute Gr√ºnde, mit dem Gendern aufzuh√∂ren:\n\n‚ÄûStudentin kann nur deshalb ‚Äöweibliche Person, die studiert‚Äò bedeuten, weil das zugrunde liegende Wort Student ‚ÄöPerson, die studiert‚Äò bedeutet und nicht etwa ‚Äöm√§nnliche Person, die studiert‚Äò‚Äú (Lieb & Richter, 1990, S. 150).\n\nNat√ºrlich lehnen auch sehr viele Frauen das Gendern ab. Pers√∂nlich kenne ich keine einzige Frau in meinem nicht-akademischen Umfeld, die Gendern gut findet.\n\nIch bin eine Frau und ich f√ºhle mich bel√§stigt von den In-Endungen, von dem Binnen-I und dem ganzen syntaktischen Gleichberechtigungsgefummel. Die fast extremistischen Z√ºge des Verweiblichungswahns von Sprache haben wohl mit der Tradition des Alice Schwarzer Opferfeminismus zu tun. Offenbar haben bis heute manche mental nicht aus der weiblichen Opferrolle herausgefunden. Als Therapie und als Beleg des weiblichen Selbstbewusstseins fordere ich das generische Maskulinum daher zur√ºck. Ich mache auch gleich ernst damit und verabschiede mich an dieser Stelle im maskulinen Gestus von Ihnen, lieber Leser, liebe B√ºrger, liebe Staatssekret√§re, liebe Feministinnen, liebe Kritiker. Das f√ºhlt sich gut an. (Dagmar Rosenfeld, in der Wochenzeitung die Zeit (2014) in einem ‚ÄûAufschrei‚Äú)\n\nInzwischen wird auch in Frage gestellt, dass das biologische Geschlecht zweiwertig ist, die Biologie an sich wird als Naturwissenschaft nicht mehr ernst genommen. Ich h√§tte nat√ºrlich nie gedacht, dass ich mich eines Tages daf√ºr rechtfertigen muss, im Statistik-Unterricht das biologische Geschlecht als Beispiel f√ºr eine zweiwertige kategoriale Variable heranzuziehen. Dazu ein Artikel aus unverd√§chtiger Quelle: Viele Geschlechter? Das ist Unfug!\nOb die extremen Anstrengungen f√ºr die so genannte Gleichstellung am Ende wirklich zielf√ºhrend sind, wage ich doch sehr stark zu bezweifeln. So haben z.B. L√§nder mit hohem Gleichstellungsaufwand eine tieferen Frauen-Anteil an MINT Hochschul-Abschl√ºssen als L√§nder, die doch eher nicht als sehr matriarchalisch gelten. Trotz massiven Anstrengungen dr√§ngen Frauen in Skandinavien wieder mehr in klassische Frauenberufe. Das sollte uns zu denken geben.\n\n\n\nGender-Equality Paradox in Science, Technology, Engineering and Mathematics. See Stoet and Geary, 2018. See also corrigendum, 2019, and reply to Richardson et al., 2020.\n\n\nIn Frankreich hat die Acad√©mie fran√ßaise erkl√§rt, das Gendern sei zur Verfolgung der damit bezweckten gesellschaftspolitischen Ziele (Gleichstellung) untauglich und kontraproduktiv. Der franz√∂sische Bildungsminister hat die Verwendung geschlechtsneutraler Schriftsprache an Schulen per Erlass verboten.\nViele lesenswerte Texte zum Thema findet man unter Gendersterntaler und LinguistikUndGendern."
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html",
    "href": "posts/fromLMtoSplines/index.html",
    "title": "Beyond linearity",
    "section": "",
    "text": "Triceps skinfold thickness dataset: The data are derived from an anthropometric study of 892 females under 50 years in three Gambian villages in West Africa.\n\nlibrary(MultiKink)\nlibrary(ggplot2)\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\n\n\ndata(\"triceps\")\nheadTail(triceps)\n\n      age lntriceps triceps\n1   12.05      1.22     3.4\n2    9.91      1.39       4\n3   10.04      1.44     4.2\n4   11.49      1.44     4.2\n...   ...       ...     ...\n889  7.91      1.92     6.8\n890  7.99      1.44     4.2\n891 14.63       2.2       9\n892 30.14       2.1     8.2\n\ntri.age.plot &lt;- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#example-data",
    "href": "posts/fromLMtoSplines/index.html#example-data",
    "title": "Beyond linearity",
    "section": "",
    "text": "Triceps skinfold thickness dataset: The data are derived from an anthropometric study of 892 females under 50 years in three Gambian villages in West Africa.\n\nlibrary(MultiKink)\nlibrary(ggplot2)\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\n\n\ndata(\"triceps\")\nheadTail(triceps)\n\n      age lntriceps triceps\n1   12.05      1.22     3.4\n2    9.91      1.39       4\n3   10.04      1.44     4.2\n4   11.49      1.44     4.2\n...   ...       ...     ...\n889  7.91      1.92     6.8\n890  7.99      1.44     4.2\n891 14.63       2.2       9\n892 30.14       2.1     8.2\n\ntri.age.plot &lt;- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#polynomial-regression",
    "href": "posts/fromLMtoSplines/index.html#polynomial-regression",
    "title": "Beyond linearity",
    "section": "Polynomial regression",
    "text": "Polynomial regression\nUsing poly() in lm():\n\nmodel.cubic.poly &lt;- lm(triceps~poly(age,3,raw=TRUE),data=triceps)\n## the same model:\n## model.cubic &lt;- lm(triceps~age + I(age^2) + I(age^3),\n##                   data=triceps)\ntri.age.plot + \n   stat_smooth(method = \"lm\", \n               formula = y~poly(x,3,raw=T), size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead."
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#cross-validation-of-different-polynomials",
    "href": "posts/fromLMtoSplines/index.html#cross-validation-of-different-polynomials",
    "title": "Beyond linearity",
    "section": "Cross-validation of different polynomials",
    "text": "Cross-validation of different polynomials\n\nRMSE for quadratic\n\nlibrary(caret)\n\nLoading required package: lattice\n\nset.seed(1234)\ntrC.lm &lt;- trainControl(method = \"repeatedcv\", \n                       number = 10,         \n                       repeats = 10)        \npol.model &lt;- train(triceps ~ poly(age,3),\n                       data = triceps, \n                       method = \"lm\",\n                       trControl = trC.lm)    \npol.model$results[2]\n\n   RMSE\n1 3.866\n\n\n\n\nRMSE for different degrees\n\nmy.pol.f &lt;- function(x){\n    xx&lt;-poly(triceps$age, x, raw=T)    \n    new.data  &lt;- cbind(triceps=triceps$triceps, xx)                                 \n    pol.model &lt;- train(triceps~., data = new.data,method = \"lm\")    \n    RMSE.cv = pol.model$results[2]\n  }\n\nt(sapply(1:10, my.pol.f))\n\n     RMSE  RMSE  RMSE RMSE  RMSE  RMSE  RMSE  RMSE  RMSE  RMSE \n[1,] 3.985 4.083 3.83 3.776 3.787 3.741 3.847 3.803 3.867 3.804\n\n\n\ntri.age.plot + \n   stat_smooth(method = \"lm\", \n               formula = y~poly(x,6,raw=T), size = 1)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#piecewise-linear-regression",
    "href": "posts/fromLMtoSplines/index.html#piecewise-linear-regression",
    "title": "Beyond linearity",
    "section": "Piecewise linear regression",
    "text": "Piecewise linear regression\nInstead of fitting a high-degree polynomial over the entire range of \\(X\\), piecewise polynomial regression involves fitting separate low-degree polynomials over different regions of \\(X\\). For example, a piecewise cubic polynomial works by fitting a cubic regression model of the form\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3x_i^3+\\epsilon_i,\\]\nwhere the coefficients differ in different parts of the range of \\(X\\). The points where the coefficients change are called knots \\(\\xi_k\\), \\(k=1,\\dots,K\\).\nLet us begin with a piecewise linear (degree=1):\n\npred1 &lt;- predict(lm(triceps~age, \n                    data = triceps[triceps$age&lt;5,]))\npred2 &lt;- predict(lm(triceps~age, \n                    data = triceps[triceps$age &gt;=5 & triceps$age&lt;10,]))\npred3 &lt;- predict(lm(triceps~age, \n                    data = triceps[triceps$age&gt;=10 & triceps$age&lt;20,]))\npred4 &lt;- predict(lm(triceps~age, \n                    data = triceps[triceps$age&gt;=20 & triceps$age&lt;30,]))\npred5 &lt;- predict(lm(triceps~age, \n                    data = triceps[triceps$age&gt;=30 & triceps$age&lt;40,]))\npred6 &lt;- predict(lm(triceps~age, \n                    data = triceps[triceps$age&gt;=40,]))\ntri.age.plot + \n  geom_line(data=triceps[triceps$age&lt;5,], \n            aes(y = pred1, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age &gt;=5 & triceps$age&lt;10,], \n            aes(y = pred2, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age&gt;=10 & triceps$age&lt;20,], \n            aes(y = pred3, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age&gt;=20 & triceps$age&lt;30,], \n            aes(y = pred4, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age&gt;=30 & triceps$age&lt;40,], \n            aes(y = pred5, x=age), size = 1, col=\"blue\") +\n  geom_line(data=triceps[triceps$age&gt;=40,], \n            aes(y = pred6, x=age), size = 1, col=\"blue\")\n\n\n\n\n\n\n\n\n\nContinuous piecewise linear regression\nWe want a continuous function. Let us define a truncated power basis function (here of degree=1) per knot \\(\\xi\\),\n\\[h(x, \\xi)=(x-\\xi)^1_{+}=\n\\begin{cases}\n  x-\\xi, \\text{\\,if\\,} x&gt;\\xi\\\\\n  0, \\text{\\,else}.\n\\end{cases}\n\\]\nThe continuous piecewise regression equation is\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2 h(x_i,5)+\\cdots+\\beta_6 h(x_i,40) + \\epsilon_i\\]\nThis can be done -by hand- or with B-splines splines::bs()\n\npred7 &lt;- predict(lm(triceps~ age + I((age-5)*(age&gt;=5)) +\n                                   I((age-10)*(age &gt;= 10)) +\n                                   I((age-20)*(age &gt;= 20)) +\n                                   I((age-30)*(age &gt;= 30)) +\n                                  I((age-40)*(age &gt;= 40)),\n                    data = triceps))\nlibrary(splines)\npred.lm.bs &lt;- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=1), data=triceps))\ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.lm.bs, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred7+.2, x=age), size = 1, col=\"red\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#splines",
    "href": "posts/fromLMtoSplines/index.html#splines",
    "title": "Beyond linearity",
    "section": "Splines",
    "text": "Splines\n\nQuadratic spline\nWith\n\\[h(x, \\xi)=(x-\\xi)_{+}^2=\n\\begin{cases}\n  (x-\\xi)^2, \\text{\\,if\\,} x&gt;\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n\\]\nwe have as regression equation \\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3 h(x_i,5)+\\cdots+\\beta_7 h(x_i,40) + \\epsilon_i\\]\n\npred.quadsmooth &lt;- predict(lm(triceps~ age + I(age^2) + \n                    I((age-5)^2*(age&gt;=5)) +\n                    I((age-10)^2*(age&gt;=10)) +\n                    I((age-20)^2*(age&gt;=20)) +\n                    I((age-30)^2*(age&gt;=30)) +\n                    I((age-40)^2*(age&gt;=40)),\n                    data = triceps))\npred.quadsmooth2 &lt;- predict(lm(triceps ~ bs(age, knots = c(5,10,20,30,40),degree=2), data=triceps))                        \ntri.age.plot +\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth, x=age), size = 1, col=\"blue\")+\n  geom_line(data=triceps, \n            aes(y = pred.quadsmooth2+.2, x=age), size = 1, col=\"red\")\n\n\n\n\n\n\n\n\n\n\nCubic Spline\nMost often, cubic splines are used. Adding the following truncated power basis function per knot,\n\\[h(x, \\xi)=(x-\\xi)_{+}^3=\n\\begin{cases}\n  (x-\\xi)^3, \\text{\\,if\\,} x&gt;\\xi\\\\\n  0, \\text{\\,else},\n\\end{cases}\n\\]\nto the model for a cubic polynomial will lead to a discontinuity in only the third derivative at \\(\\xi\\); the function will remain continuous, with continuous first and second derivatives, at each of the knots:\n\\[Y_i=\\beta_0+\\beta_1x_i+\\beta_2x_i^2+\\beta_3x_i^3+\\beta_4h(x_i,5)+\\cdots+\\beta_8h(x_i,40) + \\epsilon_i\\]\nOne can show that a cubic spline has \\(K+4\\) parameters.\n\n\nNatural Spline\nNatural splines have an additional restriction that the fitted curve linear at the extremes, splines::ns()\n\ncub.splines.bs &lt;- lm(triceps ~ bs(age, knots = c(5,10,20,30,40)), data=triceps)\ncub.splines.ns &lt;- lm(triceps ~ ns(age, knots = c(5,10,20,30,40)), data=triceps)\n\n\ntri.age.plot &lt;- ggplot(triceps, aes(x=age, y=triceps)) +\n                 geom_point(alpha=0.55, color=\"black\") + \n                 theme_minimal() \ntri.age.plot +\n    stat_smooth(method = \"lm\", \n               formula = y~bs(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"green\") + \n    stat_smooth(method = \"lm\", \n               formula = y~ns(x,knots = c(5,10,20,30,40)), \n               lty = 1, col = \"red\")\n\n\n\n\npolynomial cubic splines (green), natural cubic splines (red)"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#smoothing-splines",
    "href": "posts/fromLMtoSplines/index.html#smoothing-splines",
    "title": "Beyond linearity",
    "section": "Smoothing splines",
    "text": "Smoothing splines\nAvoids the knot selection problem completely by using a maximal set of knots. The complexity of the fit is controlled by regularization. Problem: among all functions \\(f(x)\\) with two continuous derivatives, find one that minimizes the penalized residual sum of squares\n\\[\n  RSS(f,\\lambda)=\\sum_{i=1}^N(y_i-f(x_i))^2+\\lambda[f''(t)]^2dt\n\\tag{1}\\]\nwhere \\(\\lambda\\) is a fixed smoothing parameter. The first term measures closeness to the data, while the second term penalizes curvature in the function, and \\(\\lambda\\) establishes a tradeoff between the two. Special cases: \\(\\lambda=0\\) (no constraint on \\(f\\)) and \\(\\lambda=\\infty\\) (\\(f\\) has to be linear).\nThe function \\(f(x)\\) that minimizes (Equation¬†1) can be shown to have some special properties: it is a piecewise cubic polynomial with knots at the unique values of \\(x_1,\\dots,x_n\\) and continuous first and second derivatives at each knot. Furthermore, it is linear in the region outside of the extreme knots. In other words, the function \\(f(x)\\) that minimizes (Equation¬†1) is a natural cubic spline with knots at \\(x_1,\\dots,x_n\\) ! However, it is not the same natural cubic spline that one would get if one applied the basis function approach described above ‚Äì rather, it is a shrunken version of such a natural cubic spline, where the value of the tuning parameter \\(\\lambda\\) in (Equation¬†1) controls the level of shrinkage.\nSmoothing splines are implemented in smooth.spline().\n\n\\(\\lambda\\) determined with cross-validation\n\nsspline &lt;- smooth.spline(x=triceps$age, y=triceps$triceps, cv=TRUE)\n\nWarning in smooth.spline(x = triceps$age, y = triceps$triceps, cv = TRUE): cross-validation with non-unique 'x' values seems doubtful\n\nplot(triceps$age, triceps$triceps)\nlines(sspline, lwd=3,col=\"red\")\n\n\n\n\n\n\n\n\n\n\nThe extremes: no smooth and max smooth\n\nssplineNosmooth &lt;- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=0)\nssplineMaxsmooth &lt;- smooth.spline(x=triceps$age, y=triceps$triceps, lambda=100)\nplot(triceps$age, triceps$triceps)\nlines(ssplineNosmooth, lwd=2,col=\"red\")\nlines(ssplineMaxsmooth, lwd=2,col=\"blue\")"
  },
  {
    "objectID": "posts/fromLMtoSplines/index.html#generalized-additive-model",
    "href": "posts/fromLMtoSplines/index.html#generalized-additive-model",
    "title": "Beyond linearity",
    "section": "Generalized additive model",
    "text": "Generalized additive model\nUsing mgcv::gam()\n\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\ngamtri&lt;-gam(triceps~s(age,bs=\"cr\"),data=triceps)\nsummary(gamtri)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ntriceps ~ s(age, bs = \"cr\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    9.702      0.126    77.3   &lt;2e-16\n\nApproximate significance of smooth terms:\n        edf Ref.df    F p-value\ns(age) 6.71   7.54 85.6  &lt;2e-16\n\nR-sq.(adj) =  0.419   Deviance explained = 42.3%\nGCV =  14.18  Scale est. = 14.057    n = 892\n\nplot(gamtri)"
  },
  {
    "objectID": "posts/noncollaps/index.html",
    "href": "posts/noncollaps/index.html",
    "title": "Noncollapsibility of the odds ratio",
    "section": "",
    "text": "Assume having a binary outcome \\(Y\\) and a treatment indicator \\(X\\) denoting if patient was randomised to treatment (\\(X=1\\)) or control (\\(X=0\\)). The analysis would be to fit a simple logistic regression model\n\\[\nP(Y=1|X)=\\text{expit}(\\alpha_0+\\alpha_1X),\n\\]\nwith \\(\\text{expit}(\\alpha_0+\\alpha_1X)=\\frac{\\exp(\\alpha_0+\\alpha_1X)}{1+\\exp(\\alpha_0+\\alpha_1X)}\\).\nOften, we write the model with the linear predictor, that is, the logit transformed expectation,\n\\[\n\\boxed{\\text{logit}P(Y=1|X)=\\alpha_0+{\\color{red}\\alpha_1}X}.\n\\]\nOf course, there will be other factors that influence the probability that \\(Y=1\\). Assume another variable \\(C\\) which influences the probability that \\(Y=1\\). The conditional model would be\n\\[\n\\boxed{\\text{logit}P(Y=1|X,C)=\\beta_0+{\\color{red}\\beta_1}X+\\beta_2C}.\n\\]\nNow, under randomisation, \\(C\\) and \\(X\\) are (population) independent ‚Äì that is ‚Äì there is no confounding of the effect of \\(X\\) on \\(Y\\) by \\(C\\) in place.\nThough \\(C\\) is not a confounder, in general, \\({\\color{red}\\alpha_1 \\neq \\beta_1}\\). The parameters (log odds ratios) in the marginal and conditional model are different. The proof is based on William‚Äôs Tower rule for conditional expectations:\n\\[\n\\begin{align}\nE(Y|X)=&E(E(Y|X,C)|X)\\\\\n=&E(\\text{expit}(\\beta_0+\\beta_1X+\\beta_2C)|X)\\\\\n\\neq &\\text{expit}(\\beta_0+\\beta_1X+\\beta_2E(C|X))\n\\end{align}\n\\]\n\n\n\n\n\n\n\nWith other link functions (in log-linear models) and identity (in linear models)), however, the two quantities are equal."
  },
  {
    "objectID": "posts/noncollaps/index.html#marginal-model",
    "href": "posts/noncollaps/index.html#marginal-model",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Marginal model",
    "text": "Marginal model\n\nequatiomatic::extract_eq(modM)\n\n\\[\n\\log\\left[ \\frac { P( \\operatorname{Ydich} = \\operatorname{1} ) }{ 1 - P( \\operatorname{Ydich} = \\operatorname{1} ) } \\right] = \\alpha + \\beta_{1}(\\operatorname{X})\n\\]"
  },
  {
    "objectID": "posts/noncollaps/index.html#conditional-model",
    "href": "posts/noncollaps/index.html#conditional-model",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Conditional model",
    "text": "Conditional model\n\nequatiomatic::extract_eq(modC)\n\n\\[\n\\log\\left[ \\frac { P( \\operatorname{Ydich} = \\operatorname{1} ) }{ 1 - P( \\operatorname{Ydich} = \\operatorname{1} ) } \\right] = \\alpha + \\beta_{1}(\\operatorname{X}) + \\beta_{2}(\\operatorname{C})\n\\]"
  },
  {
    "objectID": "posts/noncollaps/index.html#illustrate-non-collapsibility",
    "href": "posts/noncollaps/index.html#illustrate-non-collapsibility",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Illustrate non-collapsibility",
    "text": "Illustrate non-collapsibility\n\npred&lt;-predict(modM,type=\"response\",se.fit=TRUE)\npredgA&lt;-predict(modC,newdata=data.frame(C=C[X==0],X=0),se.fit=TRUE,type=\"response\")\npredgB&lt;-predict(modC,newdata=data.frame(C=C[X==1],X=1),se.fit=TRUE,type=\"response\")\nplot(C,Ydich,col=c(\"blue\",\"red\")[X+1],ylab=\"Probability\")\nlines(sort(C[X==0]),sort(predgA$fit),col=\"blue\")\nlines(sort(C[X==1]),sort(predgB$fit),col=\"red\")\nabline(a=mean(pii[X==0]),b=0,col=\"blue\",lty=2)\nabline(a=mean(pii[X==1]),b=0,col=\"red\",lty=2)\n\n\n\n\nLog odds ratio for group is larger when we adjust for \\(C\\) (Differences in logits between solid lines relative to distance between dashed lines)"
  },
  {
    "objectID": "posts/noncollaps/index.html#marginal-model-1",
    "href": "posts/noncollaps/index.html#marginal-model-1",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Marginal model",
    "text": "Marginal model\n\nsummary(modM)$coef\n\n            Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -0.08004     0.1415 -0.5655 0.571710\nX            0.63377     0.2040  3.1071 0.001889"
  },
  {
    "objectID": "posts/noncollaps/index.html#conditional-model-1",
    "href": "posts/noncollaps/index.html#conditional-model-1",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Conditional model",
    "text": "Conditional model\nEffect of \\(X\\) is larger, even though \\(C\\) is not a confounder. This is due to non-collapsibility of the odds ratio\n\nsummary(modC)$coef\n\n            Estimate Std. Error z value  Pr(&gt;|z|)\n(Intercept) -0.05395     0.3208 -0.1682 8.665e-01\nX            2.46270     0.5209  4.7280 2.267e-06\nC            1.04913     0.1200  8.7453 2.223e-18"
  },
  {
    "objectID": "posts/noncollaps/index.html#ipw-model",
    "href": "posts/noncollaps/index.html#ipw-model",
    "title": "Noncollapsibility of the odds ratio",
    "section": "IPW-model",
    "text": "IPW-model\nEstimate inverse probability weights to fit marginal structural models in a point treatment situation.\n\nWeights\n\nlibrary(ipw)\ntemp &lt;- ipwpoint(exposure=X,family = \"binomial\",link = \"logit\",data=dat,numerator =~1,denominator = ~ C)\nsummary(temp$ipw.weights)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.989   0.994   1.000   1.000   1.006   1.012 \n\ndat$sw&lt;-temp$ipw.weights\n\n\n\nMarginal structural model\nMarginal structural model for the causal effect of \\(X\\) on \\(Y\\) corrected for confounding by \\(C\\) using inverse probability weighting\n\nmodW&lt;-glm(Ydich~X,weights=sw,data=dat,family=quasibinomial)\nsummary(modW)$coef\n\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -0.0683     0.1419 -0.4814 0.630474\nX             0.6117     0.2043  2.9938 0.002927\n\n\n\nrequire(\"survey\")\n\nLoading required package: survey\n\n\nLoading required package: grid\n\n\nLoading required package: Matrix\n\n\nLoading required package: survival\n\n\n\nAttaching package: 'survey'\n\n\nThe following object is masked from 'package:graphics':\n\n    dotchart\n\nmsm &lt;- (svyglm(Ydich ~ X, family=\"binomial\",design = svydesign(~ 1, weights =~sw,data = dat)))\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nsummary(msm)\n\n\nCall:\nsvyglm(formula = Ydich ~ X, design = svydesign(~1, weights = ~sw, \n    data = dat), family = \"binomial\")\n\nSurvey design:\nsvydesign(~1, weights = ~sw, data = dat)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -0.0683     0.1417   -0.48   0.6301\nX             0.6117     0.2042    3.00   0.0029\n\n(Dispersion parameter for binomial family taken to be 1.003)\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "posts/noncollaps/index.html#comparison",
    "href": "posts/noncollaps/index.html#comparison",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Comparison",
    "text": "Comparison\n\nmodelsummary::modelsummary(models=list(\"marginal\"=modM,\"conditional\"=modC,\"IPW\"=modW))\n\n \n\n  \n    \n    \n    tinytable_go2gskbe8m18o691eacw\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                marginal\n                conditional\n                IPW\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -0.080  \n                  -0.054 \n                  -0.068 \n                \n                \n                             \n                  (0.142) \n                  (0.321)\n                  (0.142)\n                \n                \n                  X          \n                  0.634   \n                  2.463  \n                  0.612  \n                \n                \n                             \n                  (0.204) \n                  (0.521)\n                  (0.204)\n                \n                \n                  C          \n                          \n                  1.049  \n                         \n                \n                \n                             \n                          \n                  (0.120)\n                         \n                \n                \n                  Num.Obs.   \n                  400     \n                  400    \n                  400    \n                \n                \n                  AIC        \n                  543.4   \n                  152.6  \n                         \n                \n                \n                  BIC        \n                  551.4   \n                  164.5  \n                         \n                \n                \n                  Log.Lik.   \n                  -269.718\n                  -73.275\n                         \n                \n                \n                  F          \n                  9.654   \n                  38.281 \n                  8.963  \n                \n                \n                  RMSE       \n                  0.49    \n                  0.23   \n                  0.49   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nconditional-marginal=noncollaps+confouding\nIPW-marginal=confounding\nconditional-IPW=noncollaps"
  },
  {
    "objectID": "posts/noncollaps/index.html#simulate-some-data",
    "href": "posts/noncollaps/index.html#simulate-some-data",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Simulate some data",
    "text": "Simulate some data\n\nlibrary(simstudy)\n# define the data\ndefB &lt;- defData(varname = \"C\", formula =0.27, \n                dist = \"binary\")\ndefB &lt;- defData(defB, varname = \"Y0\", formula = \"-2.5 + 1.75*C\", \n                dist = \"binary\", link = \"logit\")\ndefB &lt;- defData(defB, varname = \"Y1\", formula = \"-1.5 + 1.75*C\", \n                dist = \"binary\", link = \"logit\")\ndefB &lt;- defData(defB, varname = \"X\", formula = \"0.315 + 0.352 *C\", \n                dist = \"binary\")\ndefB &lt;- defData(defB, varname = \"Y\", formula = \"Y0 + X * (Y1 - Y0)\", \n                dist = \"nonrandom\")\ndefB\n\n   varname            formula variance      dist     link\n    &lt;char&gt;             &lt;char&gt;    &lt;num&gt;    &lt;char&gt;   &lt;char&gt;\n1:       C               0.27        0    binary identity\n2:      Y0      -2.5 + 1.75*C        0    binary    logit\n3:      Y1      -1.5 + 1.75*C        0    binary    logit\n4:       X   0.315 + 0.352 *C        0    binary identity\n5:       Y Y0 + X * (Y1 - Y0)        0 nonrandom identity\n\n\n\nset.seed(2002)\nNnew&lt;-1000\ndtB &lt;- genData(Nnew, defB)\ndtB\n\nKey: &lt;id&gt;\n         id     C    Y0    Y1     X     Y\n      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n   1:     1     0     0     0     0     0\n   2:     2     0     0     1     0     0\n   3:     3     1     0     0     1     0\n   4:     4     0     0     0     0     0\n   5:     5     1     1     1     0     1\n  ---                                    \n 996:   996     0     0     1     0     0\n 997:   997     0     0     0     1     0\n 998:   998     1     0     1     1     1\n 999:   999     0     0     0     0     0\n1000:  1000     1     0     0     1     0"
  },
  {
    "objectID": "posts/noncollaps/index.html#true-causal-effect-based-on-potential-outcomes",
    "href": "posts/noncollaps/index.html#true-causal-effect-based-on-potential-outcomes",
    "title": "Noncollapsibility of the odds ratio",
    "section": "True causal effect (based on potential outcomes)",
    "text": "True causal effect (based on potential outcomes)\n\nodds &lt;- function (p) {\n    return((p/(1 - p)))\n}\n\ndtB[, log( odds( mean(Y1) ) / odds( mean(Y0) ) )]\n\n[1] 0.9494"
  },
  {
    "objectID": "posts/noncollaps/index.html#conditional-effect",
    "href": "posts/noncollaps/index.html#conditional-effect",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Conditional effect",
    "text": "Conditional effect\nThe true conditional causal effect of \\(A\\) is 1.\n\nmc&lt;-glm(Y ~ X + C , data = dtB, family=\"binomial\")\nmc\n\n\nCall:  glm(formula = Y ~ X + C, family = \"binomial\", data = dtB)\n\nCoefficients:\n(Intercept)            X            C  \n      -2.74         1.21         1.61  \n\nDegrees of Freedom: 999 Total (i.e. Null);  997 Residual\nNull Deviance:      964 \nResidual Deviance: 797  AIC: 803\n\n\nThis estimate for \\(X\\) is a good estimate of the conditional effect in the population, based on the potential outcomes at each level of \\(C\\)\n\ndtB[, .(LOR = log( odds( mean(Y1) ) / odds( mean(Y0) ) ) ), keyby = C]\n\nKey: &lt;C&gt;\n       C   LOR\n   &lt;int&gt; &lt;num&gt;\n1:     0 1.104\n2:     1 1.067"
  },
  {
    "objectID": "posts/noncollaps/index.html#marginal-effect",
    "href": "posts/noncollaps/index.html#marginal-effect",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Marginal effect",
    "text": "Marginal effect\nThe marginal estimate is biased both for the conditional effect and the marginal causal effect.\n\nmm&lt;-glm(Y ~ X , data = dtB, family=\"binomial\")\nmm\n\n\nCall:  glm(formula = Y ~ X, family = \"binomial\", data = dtB)\n\nCoefficients:\n(Intercept)            X  \n      -2.33         1.59  \n\nDegrees of Freedom: 999 Total (i.e. Null);  998 Residual\nNull Deviance:      964 \nResidual Deviance: 876  AIC: 880"
  },
  {
    "objectID": "posts/noncollaps/index.html#numerator-and-denominator-model",
    "href": "posts/noncollaps/index.html#numerator-and-denominator-model",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Numerator and Denominator model",
    "text": "Numerator and Denominator model\n\nnumModel &lt;- glm(X ~ 1, data = dtB, family = \"binomial\")\ndenModel &lt;- glm(X ~ C, data = dtB, family = \"binomial\")"
  },
  {
    "objectID": "posts/noncollaps/index.html#stabilized-weights-by-hand",
    "href": "posts/noncollaps/index.html#stabilized-weights-by-hand",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Stabilized weights by hand",
    "text": "Stabilized weights by hand\n\ndtB[, pX0 := predict(numModel, type = \"response\")]\ndtB[, pX := predict(denModel, type = \"response\")]\ndefB2 &lt;- defDataAdd(varname = \"IPW\", \n                    formula = \"(X*pX0+(1-X)*(1-pX0))/((X * pX) + ((1 - X) * (1 - pX)))\", \n                    dist = \"nonrandom\")\ndtB &lt;- addColumns(defB2, dtB)\ndtB[1:6]\n\nKey: &lt;id&gt;\n      id     C    Y0    Y1     X     Y   pX0     pX    IPW\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;num&gt;  &lt;num&gt;  &lt;num&gt;\n1:     1     0     0     0     0     0 0.423 0.3347 0.8673\n2:     2     0     0     1     0     0 0.423 0.3347 0.8673\n3:     3     1     0     0     1     0 0.423 0.6718 0.6297\n4:     4     0     0     0     0     0 0.423 0.3347 0.8673\n5:     5     1     1     1     0     1 0.423 0.6718 1.7578\n6:     6     1     0     0     1     0 0.423 0.6718 0.6297\n\n\n\nunique(dtB$IPW)\n\n[1] 0.8673 0.6297 1.7578 1.2639"
  },
  {
    "objectID": "posts/noncollaps/index.html#stabilized-weights-with-ipw-package",
    "href": "posts/noncollaps/index.html#stabilized-weights-with-ipw-package",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Stabilized weights with ipw package",
    "text": "Stabilized weights with ipw package\n\ntempsw&lt;-ipw::ipwpoint(exposure=X,family=\"binomial\",link=\"logit\",numerator=~1,denominator = ~C,data=dtB)\ntempw&lt;-ipw::ipwpoint(exposure=X,family=\"binomial\",link=\"logit\",denominator = ~C,data=dtB)\nunique(tempsw$ipw.weights)\n\n[1] 0.8673 0.6297 1.7578 1.2639\n\nmean(tempsw$ipw.weights)\n\n[1] 1\n\nunique(tempw$ipw.weights)\n\n[1] 1.503 1.489 3.047 2.988\n\nmean(tempw$ipw.weights)\n\n[1] 2"
  },
  {
    "objectID": "posts/noncollaps/index.html#applying-ipw",
    "href": "posts/noncollaps/index.html#applying-ipw",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Applying IPW",
    "text": "Applying IPW\n\nUnstabilized weights\n\nsummary(mw&lt;-glm(Y ~ X , data = dtB, family=\"binomial\", weights = tempw$ipw.weights))$coef\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n            Estimate Std. Error z value  Pr(&gt;|z|)\n(Intercept)   -2.069     0.1002 -20.645 1.076e-94\nX              1.081     0.1229   8.801 1.354e-18\n\n\n\n\nStabilized weights\n\nsummary(mws&lt;-glm(Y ~ X , data = dtB, family=\"binomial\", weights = tempsw$ipw.weights))$coef\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n            Estimate Std. Error z value  Pr(&gt;|z|)\n(Intercept)   -2.069     0.1319 -15.682 1.996e-55\nX              1.081     0.1713   6.312 2.760e-10"
  },
  {
    "objectID": "posts/noncollaps/index.html#comparison-1",
    "href": "posts/noncollaps/index.html#comparison-1",
    "title": "Noncollapsibility of the odds ratio",
    "section": "Comparison",
    "text": "Comparison\n\nmodelsummary::modelsummary(models=list(\"marginal\"=mm,\"conditional\"=mc,\"IPW\"=mw,\"IPWs\"=mws))\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n \n\n  \n    \n    \n    tinytable_a1qfbesdj2xn5ksy0m40\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                marginal\n                conditional\n                IPW\n                IPWs\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -2.333  \n                  -2.736  \n                  -2.069  \n                  -2.069  \n                \n                \n                             \n                  (0.147) \n                  (0.165) \n                  (0.100) \n                  (0.132) \n                \n                \n                  X          \n                  1.587   \n                  1.211   \n                  1.081   \n                  1.081   \n                \n                \n                             \n                  (0.180) \n                  (0.191) \n                  (0.123) \n                  (0.171) \n                \n                \n                  C          \n                          \n                  1.614   \n                          \n                          \n                \n                \n                             \n                          \n                  (0.183) \n                          \n                          \n                \n                \n                  Num.Obs.   \n                  1000    \n                  1000    \n                  1000    \n                  1000    \n                \n                \n                  AIC        \n                  880.1   \n                  802.5   \n                  1847.3  \n                  1004.4  \n                \n                \n                  BIC        \n                  889.9   \n                  817.3   \n                  1857.1  \n                  1014.2  \n                \n                \n                  Log.Lik.   \n                  -438.049\n                  -398.272\n                  -921.632\n                  -500.206\n                \n                \n                  F          \n                  77.828  \n                  71.500  \n                  77.460  \n                  39.837  \n                \n                \n                  RMSE       \n                  0.37    \n                  0.35    \n                  0.37    \n                  0.37"
  },
  {
    "objectID": "posts/exponentialGrowth/index.html",
    "href": "posts/exponentialGrowth/index.html",
    "title": "Exponential Growth",
    "section": "",
    "text": "The greatest shortcoming of the human race is the inability to understand the exponential function. (Al Bartlett)"
  },
  {
    "objectID": "posts/exponentialGrowth/index.html#inzidenz-und-kumulierte-inzidenz",
    "href": "posts/exponentialGrowth/index.html#inzidenz-und-kumulierte-inzidenz",
    "title": "Exponential Growth",
    "section": "Inzidenz und kumulierte Inzidenz",
    "text": "Inzidenz und kumulierte Inzidenz\n\ndata&lt;-read.csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\",check.names=FALSE)\nsw&lt;-data[data$\"Country/Region\"==\"Switzerland\",-c(1,2,3,4)]\ncases&lt;-as.numeric(sw[-c(1:42)])\nincid&lt;-diff(cases)\nt&lt;-1:length(incid)\nma &lt;- function(x, n = 7){stats::filter(x, rep(1 / n, n), sides = 2)}  ##moving average over 7 days\nincidAv&lt;-ma(incid)\nplot(t,incid,type=\"l\",col=\"blue\",lty=2,xlab=\"Tage\")\nlines(t,incidAv,col=\"red\",lwd=2)\n\n\n\n\nInzidenz\n\n\n\nplot(1:length(cases),cases,type=\"l\",col=\"blue\",lwd=2,xlab=\"Tage\")\n\n\n\n\nkumulierte Indzidenz\n\n\n\nplot(1:length(cases),log(cases),type=\"l\",col=\"blue\",lwd=2,xlab=\"Tage\")\n\n\n\n\nlog kumulierte Indzidenz"
  },
  {
    "objectID": "posts/exponentialGrowth/index.html#erste-welle-covid-19",
    "href": "posts/exponentialGrowth/index.html#erste-welle-covid-19",
    "title": "Exponential Growth",
    "section": "Erste Welle Covid-19",
    "text": "Erste Welle Covid-19\n\nswisspop&lt;-8e6\ntime&lt;-seq(1,60,by=1)\ntag&lt;-1:length(cases)\nT1&lt;-1\nT2&lt;-2\nT3&lt;-3\nT7&lt;-7\nx0&lt;-100\nY1&lt;-x0*2^(time/T1)\nY2&lt;-x0*2^(time/T2)\nY3&lt;-x0*2^(time/T3)\nY7&lt;-x0*2^(time/T7)\ntime&lt;-time+1\nplot(time,Y1,type=\"l\",ylab=\"cases\",ylim=c(100,10000),xlab=\"days\",las=1)\nlines(time,Y3,col=\"red\",lty=2)\nlines(time,Y2,lty=2)\nlines(time,Y7,lty=3)\nabline(h=swisspop,lty=5,col=\"red\") \npoints(tag,cases,type=\"l\",col=\"red\")\n\n\n\n\nInzidenz\n\n\n\nplot(time,Y1,log=\"y\",type=\"l\",ylab=\"cases\",xlab=\"days\",axes=FALSE,ylim=c(100,40000))\nat.y &lt;- outer(1:9, 10^(2:9))\nlab.y &lt;- ifelse(log10(at.y) %% 1 == 0, at.y, NA)\naxis(2, at=at.y, labels=lab.y, las=2)\naxis(1,time)\nlines(time,Y2,lty=2)\nlines(time,Y7,lty=3)\nlines(time,Y3,col=\"red\",lty=2)\nabline(h=swisspop,col=\"red\",lty=3)\npoints(tag,cases,type=\"l\",col=\"red\")\n\n\n\n\nlog Inzidenz\n\n\n\n\nErste Welle. Example of doubling times: 1 day (solid), 2 days (dashed), 3 days (red), seven days (dotted), with reported cases Covid19 in Switzerland. Horizontal line: swiss population. On a logarithmic scale, a straight line indicates exponential growth. Quelle."
  },
  {
    "objectID": "posts/exponentialGrowth/index.html#auswirkung-vorfaktor",
    "href": "posts/exponentialGrowth/index.html#auswirkung-vorfaktor",
    "title": "Exponential Growth",
    "section": "Auswirkung Vorfaktor",
    "text": "Auswirkung Vorfaktor\nAnnahme: Verdoppelung alle drei Tage, 10 Prozent der Infizierten m√ºssen ins Spital. Die Anzahl Cases von heute sind die Anzahl Spitalpatienten in 9 Tagen, wenn mann nichts macht.\n\\(0.1\\times 2^{0.33t}=0.1\\times (2^{0.33})^t=0.1\\times\n1.3^t=1.3^{\\log_{1.3}0.1}1.3^t=1.3^{t+\\log_{1.3}0.1}=1.3^{t-8.776}\\)\nAnalog kann man zeigen: Wenn die Mortalit√§tsrate bei einem Prozent der best√§tigten F√§lle liegt, dann ist die Anzahl der best√§tigten F√§lle die zu erwartende Anzahl der Todesf√§lle ca. 18 Tage sp√§ter, wenn man nichts macht.\n\\(0.01\\times 2^{0.33t}=0.01\\times (2^{0.33})^t=0.01\\times\n1.3^t=1.3^{\\log_{1.3}0.01}1.3^t=1.3^{t+\\log_{1.3}0.01}=1.3^{t-17.553}\\)\n\ndelay&lt;-log(0.1)/log(1.3)\ndelay\n\n[1] -8.776\n\ndelay2&lt;-log(0.01)/log(1.3)\ndelay2\n\n[1] -17.55\n\nplot(time,2^(0.33*time),ylab=\"cases\",xlab=\"days\",type=\"l\",ylim=c(0,10000),col=3)\nlines(time,0.1*2^(time/3),lty=1,col=1)\nlines(time,0.01*2^(time/3),lty=1,col=2,lwd=2)\n\n\n\n\nAuswirkung Vorfaktor"
  },
  {
    "objectID": "posts/exponentialGrowth/index.html#footnotes",
    "href": "posts/exponentialGrowth/index.html#footnotes",
    "title": "Exponential Growth",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nProof: \\[x(t)=x_0e^{kt}=x_0e^{t/\\tau}=x_0 2^{\\frac{t}{\\tau}\\log_2e}=x_02^{\\frac{t}{\\tau} \\frac{1}{\\log 2 }}=x_02^{t/T}\\]‚Ü©Ô∏é"
  }
]